[
  {
    "objectID": "Week11.html",
    "href": "Week11.html",
    "title": "1. Recap of the linear model and practising data-wrangling in R",
    "section": "",
    "text": "Before we start covering new material, we want to spent some time on recapping the basic concepts of the linear model (correlation, simple regression, multiple regression). You all come from different educational backgrounds and therefore have vastly different knowledge of, and experience with statistics. Therefore, please follow your own judgement as to whether you feel you want to/need to revisit material outlining the theoretical background to and the practical implementation in R for these topics. Below we provide some guidance as to materials that are relevant. Just to be clear: We don’t expect you to watch and/or read and/or do everything, please have a look at what you feel you need and spend some time with those materials."
  },
  {
    "objectID": "Week11.html#lectures",
    "href": "Week11.html#lectures",
    "title": "1. Recap of the linear model and practising data-wrangling in R",
    "section": "Lectures",
    "text": "Lectures\nThe linear model was discussed in weeks 6 to 9 of PSYC401, so that is a good place to start.\nAlternatively, if you don’t feel confident about the material, these recorded lectures might help.\n\nThe linear model: theory (~30 min) An introduction to the linear model and linear regression. I follow material as discussed in Chapter 4 of Bodo Winter’s book Statistics for Linguists: An Introduction using R (see below under ‘Reading’).\nHow to build a linear model in R (~30 min) In this video I demonstrate how to build a linear model in R by talking you through a simple linear regression script (you can download it here stats_linearModel_howTo.R). If you are unclear on what different parts of the lm() function do, or how to read the output, this video might help clarify that.\nMultiple regression: theory (~35 min) An introduction to multiple regression. I follow material as discussed in Chapter 5 of Bodo Winter’s book Statistics for Linguists: An Introduction using R (see below under ‘Reading’).\nCentering and standardising (~5 min) Brief explanation of what centering and standardising are."
  },
  {
    "objectID": "Week11.html#reading",
    "href": "Week11.html#reading",
    "title": "1. Recap of the linear model and practising data-wrangling in R",
    "section": "Reading",
    "text": "Reading\n\nMiller & Haden (2013)\nLink\nChapter 10 gives you a brief overview of what correlation and regression are. Chapter 11 introduces correlation in more detail. Chapters 12 and 14 provide accessible overviews of simple and multiple regression, respectively. All these chapters are really short but provide a good basis to understanding. We consider this the minimum level of understanding you should acquire.\n\n\nWinter (2020)\nLink\nChapter 4 provides and excellent conceptual introduction to the linear model and also explains how this is implemented in R (highly recommended).\nChapter 5 takes a slightly different approach to the one taken in Miller & Haden (2013) to introducing correlation. If you already understand the basic theory behind correlation, this will be an interesting read. Chapter 5 also clearly explains what centering and standardizing are and why you need to bother with these linear transformations.\nChapter 6 provides an excellent overview of multiple regression and also explains how this is implemented in R."
  },
  {
    "objectID": "Week11.html#pre-lab-activities",
    "href": "Week11.html#pre-lab-activities",
    "title": "1. Recap of the linear model and practising data-wrangling in R",
    "section": "Pre-lab activities",
    "text": "Pre-lab activities\nAfter having watched the lectures and read the textbook chapters you’ll be in a good position to try these activities. Completing them before you attend your lab session will help you to consolidate your learning and help move through the lab activities more smoothly.\n\nPre-lab activity 1: Visualising the regression line\nHave a look at this visualisation of the regression line by Ryan Safner.\nIn this shiny app, you see a randomly-generated set of data points (within specific parameters, to keep the graph scaled properly). You can choose a slope and intercept for the regression line by using the sliders. The graph also displays the residuals as dashed red lines. Moving the slope or the intercept too much causes the generated line to create much larger residuals. The shiny app also calculates the sum of squared errors (SSE) and the standard error of the regression (SER), which calculates the average size of the error (the red numbers). These numbers reflect how well the regression line fits the data, but you don’t need to worry about those for now.\nIn the app he uses the equation Y = aX + b in which b is the intercept and a is the slope.\nThis is slightly different from the equation you saw during the lecture. There we talked about Y = b0 + b1*X + e. Same equation, just different letters. So b0 in the lecture is equivalent to b in the app and b1 in the lecture is equivalent to a in the app.\nPre-lab activity questions:\n\nChange the slider for the intercept. How does it change the regression line?\nChange the slider for the slope. How does it change the regression line?\nWhat happens to the residuals (the red dashed lines) when you change the slope and the intercept of the regression line?\n\n\n\nPre-lab activity 2: Data-wrangling in R\nIn PSYC401, you’ve already learned how to read in data, how to select variables and how to compute summary statistics, so re-visiting the PSYC401 materials is a good place to start.\nRStudio also provides some useful interactive tutorials that take you through the basics:\n\nThe Basics Start here to learn how to inspect, visualize, subset and transform your data, as well as how to run code.\nWork with Data Learn how to extract values form a table, subset tables, calculate summary statistics, and derive new variables.\nVisualize Data Learn how to use ggplot2 to make any type of plot with your data. The tutorials on Exploratory Data Analysis and Scatterplots are particularly relevant.\n\nPlease note that there are often different ways to do the same or similar things in R. This means you might encounter slightly different functions or styles of coding in different materials. This is not something to worry about. Just make sure you’re clear on what a bit of code achieves and choose the function/style that you feel most comfortable with.\n\n\nPre-lab activity 3: Getting ready for the lab class\n\nRemind yourself of how to access and work with the RStudio Server.\n\nRevisit PSYC401 to remind yourself of how to access the RStudio Server.\n\n\n\nGet your files ready\nDownload the 402_week11_forStudents.zip file and upload it into a new folder in RStudio Server."
  },
  {
    "objectID": "Week11.html#lab-activities",
    "href": "Week11.html#lab-activities",
    "title": "1. Recap of the linear model and practising data-wrangling in R",
    "section": "Lab activities",
    "text": "Lab activities\nIn this lab, you’ll gain understanding of and practice with:\n\nwhen and why to apply simple and multiple regression to answer questions in psychological science\nconducting multiple regression in R\ninterpreting the R output of simple and multiple linear regression\nreporting results for simple and multiple linear regression following APA guidelines\n\n\nLab activity 1: Interpreting and reporting results\nHave a look at the R output below.\nR Output 1\n\n\nWhat is the outcome or dependent variable?\nWhat is the predictor or independent variable?\nIs the overall model significant?\nHow much variance does the model account for?\n\nThinking about assumptions, what do you conlcude from the plots and output below?\n\nDoes the relationship appear linear?\nDo the residuals show normality and homoscedasticity?\n\nScatterplot\n\nQQ-plot\n\nR Output 2\n\n\n\nLab activity 2: Conducting simple and multiple regression\n\nBackground\nToday, to help get a practical understanding of regression, you will be working with real data and using regression to explore the question of whether there is a relationship between voice acoustics and ratings of perceived trustworthiness.\n\nThe Voice\nThe prominent theory of voice production is the source-filter theory (Fant, 1960) which suggests that vocalisation is a two-step process: air is pushed through the larynx (vocal chords) creating a vibration, i.e. the source, and this is then shaped and moulded into words and utterances as it passes through the neck, mouth and nose, and depending on the shape of those structures at any given time you produce different sounds, i.e. the filter. One common measure of the source is pitch (otherwise called Fundamental Frequency or F0 (F-zero)) (Titze, 1994), which is a measure of the vibration of the vocal chords, in Hertz (Hz); males have on average a lower pitch than females for example. Likewise, one measure of the filter is called formant dispersion (measured again in Hz), and is effectively a measure of the length of someone’s vocal tract (or neck). Height and neck length are suggested to be negatively correlated with formant dispersion, so tall people tend to have smaller formant dispersion. So all in, the sound of your voice is thought to give some indication of what you look like.\nMore recently, work has focussed on what the sound of your voice suggests about your personality. McAleer, Todorov and Belin (2014) suggested that vocal acoustics give a perception of your trustworthiness and dominance to others, regardless of whether or not it is accurate. One extension of this is that trust may be driven by malleable aspects of your voice (e.g. your pitch) but not so much by static aspects of your voice (e.g. your formant dispersion). Pitch is considered malleable because you can control the air being pushed through your vocal chords (though you have no conscious control of your vocal chords), whereas dispersion may be controlled by the structure of your throat which is much more rigid due to muscle, bone, and other things that keep your head attached. This idea of certain traits being driven by malleable features and others by static features was previously suggested by Oosterhof and Todorov (2008) and has been tested with some validation by Rezlescu, Penton, Walsh, Tsujimura, Scott and Banissy (2015).\nSo, the research question today is: Can vocal acoustics, namely pitch and formant dispersion, predict perceived trustworthiness from a person’s voice? We will only look at male voices today, but you have the data for female voices as well should you wish to practice (note that in the field, tendency is to analyse male and female voices separately as they are effectively sexually dimorphic). As such, we hypothesise that a linear combination of pitch and dispersion will predict perceived vocal trustworthiness in male voices. This is what we will analyse.\nTo complete this lab activity, you can use the R-script (402_wk11_labAct2.R) that you downloaded as part of the ‘pre-lab activities’ as a template. Work through the activity below, adding relevant bits of code to your script as you go along.\n\n\n\nStep 1: Background and set up\n\n\n\n\n\n\nSet your working directory\n\n\n\nThe folder you were asked to download under ‘Pre-lab activity 3: Getting ready for the lab class’ contains the data files we’ll need. Make sure you have set your working directory to this folder by right-clicking on it and selecting ‘Set as working directory’.\n\n\n\n\n\n\n\n\nEmpty the R environment\n\n\n\nBefore you do anything else, when starting a new analysis, it is a good idea to empty the R environment. This prevents objects and variables from previous analyses interfering with the current one. Use the code snippet below to clear the environment.\n\n\n\nrm(list=ls())                            \n\n\n\n\n\n\n\nTip\n\n\n\nIf you hover your mouse over the box that includes the code snippet, a ‘copy to clipboard’ icon will appear in the top right corner of the box. Click that to copy the code. Now you can easily paste it into your script.\n\n\nBefore we can get started we need to tell R which libraries to use. For this analysis we’ll need broom, car, pwr and tidyverse.\n\nTASK: Load the relevant libraries. If you are unsure how to do that, you can look at the ‘Hint’ below for a clue by expanding it. After that, if you are still unsure, you can view the code by expanding the ‘Code’ section below.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the library() function.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below.\nlibrary(broom)\nlibrary(car)\nlibrary(pwr)\nlibrary(tidyverse)\n\n\n\nIn this lab, we are setting out to test whether a linear combination of pitch and dispersion will predict perceived vocal trustworthiness in male voices. We’ll be working with two data files:\n\nvoice_acoustics.csv - shows the VoiceID, the sex of the voice, and the pitch and dispersion values\nvoice_ratings.csv - shows the VoiceID and the ratings of each voice by 28 participants on a scale of 1 to 9 where 9 was extremely trustworthy and 1 was extremely untrustworthy.\n\n\nTASK: Read in both files, have a look at the layout of the data and familiarise yourself with it. The ratings data is rather messy and in a different layout to the acoustics but can you tell what is what?\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the read_csv() function.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below.\nacoustics &lt;- read_csv(\"voice_acoustics.csv\")\nratings &lt;- read_csv(\"voice_ratings.csv\")\n\n\n\n\nQUESTION 1 How are the acoustics data and the ratings data organised (wide or long)? Are both data files ‘tidy’? If you need more info on what that means, have a look here.\n\n\n\nStep 2: Restructuring the ratings data\nWe are going to need to do some data-wrangling before we do any analysis! Specifically, we need the change the ratings data to the long format.\nHere we’ll use the pivot_longer() function (see here or type ?pivot_longer in the Console for more info) to restructure the ratings data from wide to long and store the resulting table as ‘ratings_tidy’.\n\nTASK: Use the code snippet below to restructure the data. Have a look at each line of code (and the comments in green) and check that you understand how it works.\n\n\nratings_tidy &lt;- pivot_longer(\n  data = ratings,    # the data you want to restructure\n  cols = P1:P28,     # columns you want to restructure\n  names_to = \"participant\", # variable name that captures whatever is across the columns\n  # (in this case P1 to P28 for the 28 different participants)\n  values_to = \"rating\") # variable name that captures whatever is in the cells\n  # (in this case numbers for ratings)\n\n\n\nStep 3: Calculate mean trustworthiness rating for each voice\nNow that we have the ratings data into a tidy format, the next step is to calculate the mean rating for each voice. Remember that each voice is identified by the ‘VoiceID’ variable.\n\nTASK: Calculate the mean rating for each voice and store the resulting table in a variable named ‘ratings_mean’.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse group_by() and summarise(). Are you using the tidy data? Also, remember that if there are any missing values (NAs) then na.rm = TRUE would help.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nratings_mean &lt;- ratings_tidy %&gt;% \n  group_by(VoiceID) %&gt;% \n  summarise(mean_rating = mean(rating))\n\n\n\n\n\nStep 4: Join the data together\nOk, before we get ahead of ourselves, in order to perform the regression analysis we need to combine the data from ‘ratings_mean’ (the mean ratings) with ‘acoustics’ (the pitch and dispersion ratings). Also, as we said, we only want to analyse male voices today.\n\nTASK: Join the two tables and keep only the data for the male voices, call the resulting table ‘joined’.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the inner_join() function (making use of the variable that is common across both tables) to join. See here or type ?inner_join in the Console for more info. Use the filter() function to only keep male voices. Remember that the Boolean operator for exactly equal is ==.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\njoined &lt;- ratings_mean %&gt;%\n  inner_join(acoustics, \"VoiceID\") %&gt;% \n  filter(sex == \"M\")\n\n\n\n\n\nStep 5: Spreading the data\nWe are starting to get an understanding of our data and we want to start thinking about the regression. However, the regression would be easier to work with if Pitch and Dispersion were in separate columns. This can be achieved using the pivot_wider() function (see here or type ?pivot_wider in the Console for more info). This is basically the inverse of pivot_longer(). It increases the number of columns and decreases the number of rows.\n\nTASK: Use the code snippet below to spread the data. Have a look at each line of code (and the comments in green) and check that you understand how it works.\n\n\njoined_wide &lt;- joined %&gt;%\n  pivot_wider(\n    names_from = measures, # name of the categorical column to spread\n    values_from = value) # name of the data to spread\n\n\nQUESTION 2 Why do we not need to specify within the pivot_wider() function which data to use?\n\n\n\nStep 6: Visualising the data\nAs always, it is a good idea to visualise your data.\n\nTASK: Now that we have all the variables in one place, make two scatterplots, one of mean trustworthiness rating with dispersion and one for mean trustworthiness rating and pitch.\n\n\n\n\n\n\n\nHint 1\n\n\n\n\n\nFor this you’ll need the ggplot() function together with geom_point() and geom_smooth(). Make sure to give your axes some sensible labels.\n\n\n\n\n\n\n\n\n\nHint 2\n\n\n\n\n\nBelow is a template for the code. Make sure to specify the data frame and the relevant variables.\nggplot(DATA, aes(x = variable X, y = variable Y)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  theme_bw() +\n  labs (y = \"Label for variable Y\")\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nggplot(joined_wide, aes(x = Dispersion, y = mean_rating)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  theme_bw() +\n  labs (y = \"Mean Trustworthiness Rating\")\n\nggplot(joined_wide, aes(x = Pitch, y = mean_rating)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  theme_bw() +\n  labs (y = \"Mean Trustworthiness Rating\")\n\n\n\n\nQUESTION 3 According to the scatterplots, how would you describe the relationships between trustworthiness and dispersion and trustworthiness and pitch in terms of direction and strength? Which one of the two seems stronger?\n\n\n\nStep 7: Conducting and interpreting simple regression\nWith all the variables in place and having gained a better understanding of our data by inspecting the scatterplots, we’re ready now to start building two simple linear regression models:\n\nPredicting trustworthiness mean ratings from Pitch\nPredicting trustworthiness mean ratings from Dispersion\n\n\nTASK: Use the lm() function to run the following two regression models and use the summary() function to look at the output of each model. Store the first model in a table called ‘mod_pitch’ and store the second model in ‘mod_disp’.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nBelow is a template for the code. Make sure to specify the data frame and the relevant variables.\nlm(dv ~ iv, data = my_data)\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nmod_disp &lt;- lm(mean_rating ~ Dispersion, joined_wide)\nmod_disp_sum &lt;- summary(mod_disp)\n\nmod_pitch &lt;- lm(mean_rating ~ Pitch, joined_wide)\nmod_pitch_sum &lt;- summary(mod_pitch)\n\n\n\n\nQUESTION 4 What do you conclude from the output of these models? Which model is significant? Which predictors are significant? How much variance does each model describe?\n\n\n\nStep 8: Conducting and interpreting multiple regression\nNow let’s look at both predictors in the same model. Before we do this, it is sensible to center and standardise the predictors.\nLook at the code below. Can you follow how the predictors are first centered (_c) and then standardised (_z)?\nHere I do this by hand because I think it makes it clearer, even though there are functions that do this in one step (scale()).\n\njoined_wide &lt;- mutate(joined_wide,\n                      Dispersion_c = Dispersion - mean(Dispersion),\n                      Dispersion_z = Dispersion_c / sd(Dispersion_c),\n                      Pitch_c = Pitch - mean(Pitch),\n                      Pitch_z = Pitch_c / sd(Pitch_c))\n\n\nTASK: Now use the centered and standardised data for the multiple regression. Use the lm() function to run a model for predicting trustworthiness mean ratings from Pitch and Dispersion, and store the model in ‘mod_pitchdisp_z’. Use the ‘summary()’ function to look at the output.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nBelow is a template for the code. Make sure to specify the data frame and the relevant variables.\nlm(dv ~ iv1 + iv2, data = my_data)\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nmod_pitchdisp_z &lt;- lm(mean_rating ~ Pitch_z + Dispersion_z, joined_wide)\nmod_pitchdisp_z_sum &lt;- summary(mod_pitchdisp_z)\n\n\n\n\nQUESTION 5 What do you conclude from the output of this model? Is the overall model significant? Which predictors are significant? How much variance does the model describe? Which model would you say is best for predicting ratings of trustworthiness, the Pitch only, the Dispersion only or the Pitch+Dispersion model?\n\n\n\nStep 9: Checking assumptions\nNow that we’ve established which model best fits the data, let’s check whether it meets the assumptions of linearity, normality and homoscedasticity.\n\nTASK: Check the assumptions of linearity, normality and homoscedasticity.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou can use the crPlots() and the qqPlot() functions to check linearity. The shapiro.test() can be used to check normality of the residuals and the residualPlot() and nvcTest() functions to check homoscedasticity of the residuals. These plots are from base R rather than using the ggplot() function. See [here] (https://r4ds.hadley.nz/base-r#plots) for a brief explanation of base R plots and why you might want to use them.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\ncrPlots(mod_pitch)\n\nqqPlot(mod_pitch$residuals) \nshapiro.test(mod_pitch$residuals)\n\nresidualPlot(mod_pitch)\nncvTest(mod_pitch)\n\n\n\n\nQUESTION 6 What do you conclude from the graphs and output? Should we also check for collinearity?\n\n\n\nStep 10: Writing up the results\n\nTASK: Write up the results following APA guidelines.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nThe Purdue writing lab website is helpful for guidance on punctuating statistics. The APA Style 7th Edition Numbers and Statistics Guide is also useful."
  },
  {
    "objectID": "Week11.html#answers",
    "href": "Week11.html#answers",
    "title": "1. Recap of the linear model and practising data-wrangling in R",
    "section": "Answers",
    "text": "Answers\nWhen you have completed all of the lab content, you may want to check your answers with our completed version of the script for this week. Remember, looking at this script (studying/revising it) does not replace the process of working through the lab activities, trying them out for yourself, getting stuck, asking questions, finding solutions, adding your own comments, etc. Actively engaging with the material is the way to learn these analysis skills, not by looking at someone else’s completed code…\nThe answers to the questions and the script containing the code will be available after lab session has taken place."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Analysing and Interpreting Psychological Data II",
    "section": "",
    "text": "Welcome\nWelcome to PSYC402!\nThis module builds on the knowledge and skills acquired in Statistics for Psychologists 1 (PSYC401). You will continue to practise data handling, data processing and data visualisation, using R and R Studio. In addition, you will extend your knowledge of the general linear model and learn how to adapt it when working with different types of data. Of course you’ll also learn how to implement those methods in R and R Studio.\nThis page gives you access to all the materials that you will need. You will have timetabled lab classes during which you are expected to work through a series of exercises to practise that week’s material. Before you come to your lab session, you should watch the lectures for that week, read the relevant book chapter and complete the pre-lab activities.\n\n\nAsking for help\nWe have carefully prepared and refined the lab materials in this course over several years, and we feel that the pace of the materials is just right for our students. Some students will complete them more quickly, and others more slowly - both of these scenarios are absolutely fine. You should work at the pace that suits you best, making sure you understand the materials before you move forward.\nIt is fairly inevitable that you will get stuck on the lab materials in this module at some point. This might be in Week 11, Week 12, or later. When you do, it’s important you reach out for help:\n\nAsk your friends on your table. We’ve designed this teaching space to help collaborative work. You are encouraged to work with other students. Make sure you ask others to explain how they’ve solved an exercise. Make sure you help out others where you can. Always make sure you understand the code and the exercise; don’t simply be satisfied that you’ve got the right answer.\nAsk a GTA or Lecturer. Our teaching staff is there to help you. There are no “stupid questions” in statistics, so just ask the GTA or the lecturer any question about what you’re doing.\nAsk on the Discussion Forum. On the PSYC402 moodle page you will find a Discussion Forum. This is a great way to ask a question outside of the lab sessions. It might seem scary to ask a question in the forum, but please don’t be afraid to do this. If you have a question, you can bet other students also have the same question! So by asking the question on the forum, you help out many more people on the module. A friendly GTA or Lecturer will be along to answer the question as soon as possible (we aim for within 48 hours during the working week).\nAsk on the module Q & A session. Each week we hold a “Q&A” online session where we will try and resolve any general queries and problems. It’s an ideal time to discuss things that students are struggling with or confused about, and can share ideas and answers. You can ask on the discussion forum above and then we might be able to pick up the issues and discuss them, but also you can ask in the session itself.\n\n\n\nCourse Contacts\n\n\n\n\nEmail Address\n\n\n\n\nMargriet Groen\nm.groen at lancaster dot ac dot uk\n\n\nRob Davies\nr.davies1 at lancaster dot ac dot uk\n\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "References\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Week11.html#empty-the-r-environment",
    "href": "Week11.html#empty-the-r-environment",
    "title": "1. Recap of the linear model and practising data-wrangling in R",
    "section": "Empty the R environment",
    "text": "Empty the R environment\nBefore you do anything else, when starting a new analysis, it is a good idea to empty the R environment. This prevents objects and variables from previous analyses interfering with the current one. Use the code snippet below to clear the environment."
  }
]