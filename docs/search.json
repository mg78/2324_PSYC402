[
  {
    "objectID": "Week15.html",
    "href": "Week15.html",
    "title": "5. Poisson regression",
    "section": "",
    "text": "Previously, we looked at logistic regression in the context of a binomial outcome variable, that is, a two-level variable such as correct vs. incorrect, or looking to the left vs. the right. Poisson regression is another type of generalized linear model that is particularly useful for count data."
  },
  {
    "objectID": "Week15.html#lectures",
    "href": "Week15.html#lectures",
    "title": "5. Poisson regression",
    "section": "Lectures",
    "text": "Lectures\nThe lecture material for this week follows the recommended chapters in Winter (2020) – see under ‘Reading’ below – and is presented below:\nPoisson regression (~28 min)\n\nSlides Transcript"
  },
  {
    "objectID": "Week15.html#reading",
    "href": "Week15.html#reading",
    "title": "5. Poisson regression",
    "section": "Reading",
    "text": "Reading\n\nWinter (2020)\nLink\nChapter 13 provides a clear introduction to Poisson regression and its implementation in R."
  },
  {
    "objectID": "Week15.html#pre-lab-activities",
    "href": "Week15.html#pre-lab-activities",
    "title": "5. Poisson regression",
    "section": "Pre-lab activities",
    "text": "Pre-lab activities\nAfter having watched the lectures and read the textbook chapters you’ll be in a good position to try these activities. Completing them before you attend your lab session will help you to consolidate your learning and help move through the lab activities more smoothly.\n\nPre-lab activity 1: Getting a feel for Poisson data\nTo get a feel for Poisson data, we’ll use the rpois() function to generate random data that is Poisson-distributed. rpois() needs two bits of information: lambda, and how many numbers you want to generate.\nAs usual, before we get stuck in we need to set up a few things.\n\nTASK: Add code to clear the environment. HINT: rm(list=ls())\n\nNext we need to tell R which libraries to use. For this pre-lab activity, we just need the tidyverse library.\n\nTASK: Add code to load relevant libraries. HINT: library()\n\nOk, now let’s play around with different lambdas to get a feel for the Poisson distribution.\n\nTASK: Copy the code below to your script and run it. Then change the value of lambda in the rpois() function and see how the distribution changes.\n\n\nlambda2 &lt;- rpois(n = 1000, lambda = 2)\n\nlambda2 &lt;- as.data.frame(lambda2)\n\nggplot(data = lambda2, mapping = aes(x = lambda2)) +\n  geom_bar()\n\nQUESTION: What do you notice about the Poisson distribution if you choose a high value for lambda?\n\n\nPre-lab activity 2: Getting ready\n\nGet your files ready\nDownload the 402_week15_forStudents.zip file and upload it into a new folder in RStudio Server.\n\n\nRemind yourself of how to access and work with the RStudio Server.\n\nSign in to the RStudio Server. Note that when you are not on campus you need to log into the VPN first (look on the portal if you need more information about that).\nCreate a new folder for this week’s work.\nUpload the zip-file to the folder you have created on the RStudio server. Note you can either upload a single file or a zip-file.\n\n\n\n\n\n\n\nIf you have difficulty uploading files to the server\n\n\n\nIf you get error messages when attempting to upload a file or a folder with files to the server, you can try the following steps:\n\nClose the R Studio server, close your browser and start afresh.\nOpen the R Studio server in a different browser.\nFollow a work around where you use code to directly download the file to the server. The code to do that will be available at the start of the lab activity where you need that particular file. The code to download the file you need to complete the quiz is below."
  },
  {
    "objectID": "Week15.html#lab-activities",
    "href": "Week15.html#lab-activities",
    "title": "5. Poisson regression",
    "section": "Lab activities",
    "text": "Lab activities\nIn this lab, you’ll gain understanding of and practice with:\n\nwhen and why to apply Poisson regression to answer questions in psychological science\nconducting Poisson regression in R\ninterpreting the R output of Poisson regression\nreporting results for Poisson regression following APA guidelines\n\n\nLab activity 1: Visual dominance\nWinter et al. (2018) showed that, on average, English words that were rated as strongly associated with the visual modality are more frequent than words more strongly associated with other sensory modalities. In this week’s lab activity we will retrace that analysis focusing on the subset of adjectives (the paper also included verbs and nouns). We’ll use sensory modality ratings as reported by Lynott and Connell (2009; see here for more info; data file: lynott_connell_2009_modality.csv) and word frequencies as reported by the English Lexicon Project (data file: ELP_full_length_frequency.csv). The research question is: Do English speakers use ‘visual’ adjectives more frequently than adjectives more strongly associated with other sensory modalities?\n\nStep 1: Set up\n\n\n\n\n\n\nSet your working directory\n\n\n\nThe folder you were asked to download under ‘Pre-lab activity 2: Getting ready for the lab class’ contains the data files we’ll need. Make sure you have set your working directory to this folder by right-clicking on it and selecting ‘Set as working directory’.\n\n\n\n\n\n\n\n\nEmpty the R environment\n\n\n\nBefore you do anything else, when starting a new analysis, it is a good idea to empty the R environment. This prevents objects and variables from previous analyses interfering with the current one. To do this, you can click on the little broom icon in the top right of the Environment pane, or you can use rm(list=ls()).\n\n\nBefore we can get started we need to tell R which libraries to use. For this analysis we’ll need broom, tidyverse, MASS and pscl.\n\nTASK: Load the relevant libraries. If you are unsure how to do that, you can look at the ‘Hint’ below for a clue by expanding it. After that, if you are still unsure, you can view the code by expanding the ‘Code’ section below.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the library() function.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below.\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(MASS)\nlibrary(pscl)\n\n\n\n\n\n\n\n\n\nIf you couldn’t upload files to the server, do this:\n\n\n\nIf you experienced difficulties with uploading a folder or a file to the server, you can use the code below to directly download the file you need in this lab activity to the server (instead of first downloading it to you computer and then uploading it to the server). Remember that you can copy the code to your clipboard by clicking on the ‘clipboard’ in the top right corner.\n\n\n\ndownload.file(\"https://github.com/mg78/2324_PSYC402/blob/main/data/week15/402_week15_forStudents/ELP_full_length_frequency.csv?raw=true\", destfile = \"ELP_full_length_frequency.csv\")\n\n\ndownload.file(\"https://github.com/mg78/2324_PSYC402/blob/main/data/week15/402_week15_forStudents/lynott_connell_2009_modality.csv?raw=true\", destfile = \"lynott_connell_2009_modality.csv\")\n\n\nTASK: Finally, read in the two data files (lynott_connell_2009_modality.csv and ELP_full_length_frequency.csv) and have a look at them.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the read_csv() function and the head() function.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below.\nlyn &lt;- read_csv('lynott_connell_2009_modality.csv')\nELP &lt;- read_csv('ELP_full_length_frequency.csv')\nhead(lyn)\nhead(ELP)\n\n\n\nQUESTION 1: Which variables do you need to address the research question?\n\n\nStep 2: A bit of data wrangling\nWe need to combine the information in the data files to be able to do any analyses. We can use a ‘join’ to do this. Have a look at the online book by Hadley Wickam and Gareth Grolemund (here) to remind yourself what a ‘join’ is. In particular, have a look at the inner_join() and the left_join().\nQUESTION 2: Which ‘join’ is most appropriate, the inner_join() or the left_join()? Also, does it matter which data file you specify as x and which one as y? If so, why does it matter?\n\nTASK: Add code to join the two data files and store the resulting table in an object called both. Try out the different joins and use head() to inspect the result.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou should end up with a table that has 423 observations of at least 8 variables.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nboth &lt;- left_join(x = lyn, y = ELP, by = 'Word')\n\n\n\nNext, we want to select only the variables we need. We want to use the select() function from dplyr. Because the MASS library is also loaded and that library also contains a select() function, we need to tell R specifically to use the one from dplyr. You can do this by using dpply::, like this:\n\nboth &lt;- dplyr::select(Word, DominantModality:Smell, Log10Freq)\n\n\nTASK: Add the code above to your script and run it.\n\nFinally, to apply Poisson regression, we need the frequency variable as positive integers.\n\nTASK: Use the code below to transform the frequency variable to raw values. Don’t forget to add it to your script and run it.\n\n\nboth &lt;- mutate(both, Freq = 10 ^ Log10Freq)\n\nQUESTION 3: What does this line of code do. Write a comment to summarise its function.\n\n\nStep 3: Visualise the data\nTo get a better feel for the data, let’s make some scatterplots.\n\nTASK: Add code to make scatterplots with Freq on the y axis and each of the sensory modality ratings on the respective x axis. To be able to see more easily what is going on, limit the y-axis to values between 0 and 20000.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nMake 5 different scatterplots using ggplot() withgeom_point() and geom_smooth(). You can use ylim() to limit the values on the y-axis.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nggplot(both, aes(x = Sight, y = Freq)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = TRUE) +\n  theme_bw() +\n  ylim(c(0, 20000))\n\nggplot(both, aes(x = Touch, y = Freq)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = TRUE) +\n  theme_bw()  +\n  ylim(c(0, 20000))  \n\nggplot(both, aes(x = Sound, y = Freq)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = TRUE) +\n  theme_bw() +\n  ylim(c(0, 20000))\n\nggplot(both, aes(x = Taste, y = Freq)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = TRUE) +\n  theme_bw() +\n  ylim(c(0, 20000))\n\nggplot(both, aes(x = Smell, y = Freq)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = TRUE) +\n  theme_bw() +\n  ylim(c(0, 20000))\n\n\n\nQUESTION 4: What do you conclude from the scatterplots?\n\n\nStep 4: The regression model\nWe are going to fit a Poisson regression model with Taste, Smell, Touch, Sight and Sound as predictors (all of these are continuous rating scales).\n\nTASK: Fit a Poisson regression model for ‘Freq’ as a function of ‘Taste’, ‘Smell’, ‘Touch’, ‘Sight’ and ‘Sound’.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the glm() function with family = poisson.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nfreqMod &lt;- glm(Freq ~ Sight + Taste + Smell + Sound + Touch,\n               data = both,\n               family = poisson)\n\nsummary(freqMod)\n\n\n\nQUESTION 5: How do you interpret the output of the Poisson regression?\n\n\nStep 5: Overdispersion\nIn the lecture we saw that it is possible that the variance is larger than theoretically expected for a given lambda. If this happens, we are dealing with what’s called ‘overdispersion’. You can compensate for this by using a variant of Poisson regression that is called ‘negative binomial regression’. In negative binomial regression the variance is uncouples from the mean.\n\nTASK: Fit a negative binomial regression model for ‘Freq’ as a function of ‘Taste’, ‘Smell’, ‘Touch’, ‘Sight’ and ‘Sound’.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the glm.nb() function.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nfreqMod_nb &lt;- glm.nb(Freq ~ Sight + Taste + Smell + Sound + Touch,\n    data = both)\nsummary(freqMod_nb)\n\n\n\nNext, check whether there is significant overdispersion by performing a likelihood ratio test, comparing the likelihood of the negative binomial model against the likelihood of the corresponding Poisson model.\n\nTASK: Use the odTest() function to perform an ‘overdispersion’ test.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the odTest() function and pass object that identifies your model as the argument.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nodTest(freqMod_nb)\n\n\n\nQUESTION 6: What do you conclude from the results of the overdispersion test?\nQUESTION 7: How do you interpret the negative binomial regression output? Do English speakers use visual adjectives more frequently? What about smell adjectives in comparison?"
  },
  {
    "objectID": "Week15.html#answers",
    "href": "Week15.html#answers",
    "title": "5. Poisson regression",
    "section": "Answers",
    "text": "Answers\nWhen you have completed all of the lab content, you may want to check your answers with our completed version of the script for this week. Remember, looking at this script (studying/revising it) does not replace the process of working through the lab activities, trying them out for yourself, getting stuck, asking questions, finding solutions, adding your own comments, etc. Actively engaging with the material is the way to learn these analysis skills, not by looking at someone else’s completed code…\nThe answers to the questions and the script containing the code will be available after the lab session has taken place."
  },
  {
    "objectID": "Week11.html",
    "href": "Week11.html",
    "title": "1. Recap of the linear model and practising data-wrangling in R",
    "section": "",
    "text": "Before we start covering new material, we want to spent some time on recapping the basic concepts of the linear model (correlation, simple regression, multiple regression). You all come from different educational backgrounds and therefore have vastly different knowledge of, and experience with statistics. Therefore, please follow your own judgement as to whether you feel you want to/need to revisit material outlining the theoretical background to and the practical implementation in R for these topics. Below we provide some guidance as to materials that are relevant. Just to be clear: We don’t expect you to watch and/or read and/or do everything, please have a look at what you feel you need and spend some time with those materials."
  },
  {
    "objectID": "Week11.html#sec-wk11-lectures",
    "href": "Week11.html#sec-wk11-lectures",
    "title": "1. Recap of the linear model and practising data-wrangling in R",
    "section": "Lectures",
    "text": "Lectures\nThe linear model was discussed in weeks 6 to 9 of PSYC401, so that is a good place to start.\nAlternatively, if you don’t feel confident about the material, these recorded lectures might help.\n\nThe linear model: theory (~30 min) An introduction to the linear model and linear regression. I follow material as discussed in Chapter 4 of Bodo Winter’s book Statistics for Linguists: An Introduction using R (see below under ‘Reading’).\nHow to build a linear model in R (~14 min) In this video I demonstrate how to build a linear model in R by talking you through a simple linear regression script (you can download it by clicking on the link below the video). If you are unclear on what different parts of the lm() function do, or how to read the output, this video might help clarify that.\n\n\nSlides Transcript Example R-script\n\nMultiple regression: theory (~35 min) An introduction to multiple regression. I follow material as discussed in Chapter 5 of Bodo Winter’s book Statistics for Linguists: An Introduction using R (see below under ‘Reading’).\nCentering and standardising (~5 min) Brief explanation of what centering and standardising are."
  },
  {
    "objectID": "Week11.html#sec-wk11-reading",
    "href": "Week11.html#sec-wk11-reading",
    "title": "1. Recap of the linear model and practising data-wrangling in R",
    "section": "Reading",
    "text": "Reading\n\nMiller & Haden (2013)\nLink\nChapter 10 gives you a brief overview of what correlation and regression are. Chapter 11 introduces correlation in more detail. Chapters 12 and 14 provide accessible overviews of simple and multiple regression, respectively. All these chapters are really short but provide a good basis to understanding. We consider this the minimum level of understanding you should acquire.\n\n\nWinter (2020)\nLink\nChapter 4 provides and excellent conceptual introduction to the linear model and also explains how this is implemented in R (highly recommended).\nChapter 5 takes a slightly different approach to the one taken in Miller & Haden (2013) to introducing correlation. If you already understand the basic theory behind correlation, this will be an interesting read. Chapter 5 also clearly explains what centering and standardizing are and why you need to bother with these linear transformations.\nChapter 6 provides an excellent overview of multiple regression and also explains how this is implemented in R."
  },
  {
    "objectID": "Week11.html#sec-wk11-pre-labactvities",
    "href": "Week11.html#sec-wk11-pre-labactvities",
    "title": "1. Recap of the linear model and practising data-wrangling in R",
    "section": "Pre-lab activities",
    "text": "Pre-lab activities\nAfter having watched the lectures and read the textbook chapters you’ll be in a good position to try these activities. Completing them before you attend your lab session will help you to consolidate your learning and help move through the lab activities more smoothly.\n\nPre-lab activity 1: Visualising the regression line\nHave a look at this visualisation of the regression line by Ryan Safner.\nIn this shiny app, you see a randomly-generated set of data points (within specific parameters, to keep the graph scaled properly). You can choose a slope and intercept for the regression line by using the sliders. The graph also displays the residuals as dashed red lines. Moving the slope or the intercept too much causes the generated line to create much larger residuals. The shiny app also calculates the sum of squared errors (SSE) and the standard error of the regression (SER), which calculates the average size of the error (the red numbers). These numbers reflect how well the regression line fits the data, but you don’t need to worry about those for now.\nIn the app he uses the equation Y = aX + b in which b is the intercept and a is the slope.\nThis is slightly different from the equation you saw during the lecture. There we talked about Y = b0 + b1*X + e. Same equation, just different letters. So b0 in the lecture is equivalent to b in the app and b1 in the lecture is equivalent to a in the app.\nPre-lab activity questions:\n\nChange the slider for the intercept. How does it change the regression line?\nChange the slider for the slope. How does it change the regression line?\nWhat happens to the residuals (the red dashed lines) when you change the slope and the intercept of the regression line?\n\n\n\nPre-lab activity 2: Data-wrangling in R\nIn PSYC401, you’ve already learned how to read in data, how to select variables and how to compute summary statistics, so re-visiting the PSYC401 materials is a good place to start.\nRStudio also provides some useful interactive tutorials that take you through the basics:\n\nThe Basics Start here to learn how to inspect, visualize, subset and transform your data, as well as how to run code.\nWork with Data Learn how to extract values form a table, subset tables, calculate summary statistics, and derive new variables.\nVisualize Data Learn how to use ggplot2 to make any type of plot with your data. The tutorials on Exploratory Data Analysis and Scatterplots are particularly relevant.\n\nPlease note that there are often different ways to do the same or similar things in R. This means you might encounter slightly different functions or styles of coding in different materials. This is not something to worry about. Just make sure you’re clear on what a bit of code achieves and choose the function/style that you feel most comfortable with.\n\n\nPre-lab activity 3: Getting ready for the lab class\n\nRemind yourself of how to access and work with the RStudio Server.\n\nRevisit PSYC401 to remind yourself of how to access the RStudio Server.\n\n\n\nGet your files ready\nDownload the 402_week11_forStudents.zip file and upload it into a new folder in RStudio Server."
  },
  {
    "objectID": "Week11.html#sec-wk11-labactivities",
    "href": "Week11.html#sec-wk11-labactivities",
    "title": "1. Recap of the linear model and practising data-wrangling in R",
    "section": "Lab activities",
    "text": "Lab activities\nIn this lab, you’ll gain understanding of and practice with:\n\nwhen and why to apply simple and multiple regression to answer questions in psychological science\nconducting multiple regression in R\ninterpreting the R output of simple and multiple linear regression\nreporting results for simple and multiple linear regression following APA guidelines\n\n\nLab activity 1: Interpreting and reporting results\nHave a look at the R output below.\nR Output 1\n\n\nWhat is the outcome or dependent variable?\nWhat is the predictor or independent variable?\nIs the overall model significant?\nHow much variance does the model account for?\n\nThinking about assumptions, what do you conlcude from the plots and output below?\n\nDoes the relationship appear linear?\nDo the residuals show normality and homoscedasticity?\n\nScatterplot\n\nQQ-plot\n\nR Output 2\n\n\n\nLab activity 2: Conducting simple and multiple regression\n\nBackground\nToday, to help get a practical understanding of regression, you will be working with real data and using regression to explore the question of whether there is a relationship between voice acoustics and ratings of perceived trustworthiness.\n\nThe Voice\nThe prominent theory of voice production is the source-filter theory (Fant, 1960) which suggests that vocalisation is a two-step process: air is pushed through the larynx (vocal chords) creating a vibration, i.e. the source, and this is then shaped and moulded into words and utterances as it passes through the neck, mouth and nose, and depending on the shape of those structures at any given time you produce different sounds, i.e. the filter. One common measure of the source is pitch (otherwise called Fundamental Frequency or F0 (F-zero)) (Titze, 1994), which is a measure of the vibration of the vocal chords, in Hertz (Hz); males have on average a lower pitch than females for example. Likewise, one measure of the filter is called formant dispersion (measured again in Hz), and is effectively a measure of the length of someone’s vocal tract (or neck). Height and neck length are suggested to be negatively correlated with formant dispersion, so tall people tend to have smaller formant dispersion. So all in, the sound of your voice is thought to give some indication of what you look like.\nMore recently, work has focussed on what the sound of your voice suggests about your personality. McAleer, Todorov and Belin (2014) suggested that vocal acoustics give a perception of your trustworthiness and dominance to others, regardless of whether or not it is accurate. One extension of this is that trust may be driven by malleable aspects of your voice (e.g. your pitch) but not so much by static aspects of your voice (e.g. your formant dispersion). Pitch is considered malleable because you can control the air being pushed through your vocal chords (though you have no conscious control of your vocal chords), whereas dispersion may be controlled by the structure of your throat which is much more rigid due to muscle, bone, and other things that keep your head attached. This idea of certain traits being driven by malleable features and others by static features was previously suggested by Oosterhof and Todorov (2008) and has been tested with some validation by Rezlescu, Penton, Walsh, Tsujimura, Scott and Banissy (2015).\nSo, the research question today is: Can vocal acoustics, namely pitch and formant dispersion, predict perceived trustworthiness from a person’s voice? We will only look at male voices today, but you have the data for female voices as well should you wish to practice (note that in the field, tendency is to analyse male and female voices separately as they are effectively sexually dimorphic). As such, we hypothesise that a linear combination of pitch and dispersion will predict perceived vocal trustworthiness in male voices. This is what we will analyse.\nTo complete this lab activity, you can use the R-script (402_wk11_labAct2.R) that you downloaded as part of the ‘pre-lab activities’ as a template. Work through the activity below, adding relevant bits of code to your script as you go along.\n\n\n\nStep 1: Background and set up\n\n\n\n\n\n\nSet your working directory\n\n\n\nThe folder you were asked to download under ‘Pre-lab activity 3: Getting ready for the lab class’ contains the data files we’ll need. Make sure you have set your working directory to this folder by right-clicking on it and selecting ‘Set as working directory’.\n\n\n\n\n\n\n\n\nEmpty the R environment\n\n\n\nBefore you do anything else, when starting a new analysis, it is a good idea to empty the R environment. This prevents objects and variables from previous analyses interfering with the current one. Use the code snippet below to clear the environment.\n\n\n\nrm(list=ls())                            \n\n\n\n\n\n\n\nTip\n\n\n\nIf you hover your mouse over the box that includes the code snippet, a ‘copy to clipboard’ icon will appear in the top right corner of the box. Click that to copy the code. Now you can easily paste it into your script.\n\n\nBefore we can get started we need to tell R which libraries to use. For this analysis we’ll need broom, car, pwr and tidyverse.\n\nTASK: Load the relevant libraries. If you are unsure how to do that, you can look at the ‘Hint’ below for a clue by expanding it. After that, if you are still unsure, you can view the code by expanding the ‘Code’ section below.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the library() function.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below.\nlibrary(broom)\nlibrary(car)\nlibrary(pwr)\nlibrary(tidyverse)\n\n\n\nIn this lab, we are setting out to test whether a linear combination of pitch and dispersion will predict perceived vocal trustworthiness in male voices. We’ll be working with two data files:\n\nvoice_acoustics.csv - shows the VoiceID, the sex of the voice, and the pitch and dispersion values\nvoice_ratings.csv - shows the VoiceID and the ratings of each voice by 28 participants on a scale of 1 to 9 where 9 was extremely trustworthy and 1 was extremely untrustworthy.\n\n\nTASK: Read in both files, have a look at the layout of the data and familiarise yourself with it. The ratings data is rather messy and in a different layout to the acoustics but can you tell what is what?\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the read_csv() function.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below.\nacoustics &lt;- read_csv(\"voice_acoustics.csv\")\nratings &lt;- read_csv(\"voice_ratings.csv\")\n\n\n\n\nQUESTION 1 How are the acoustics data and the ratings data organised (wide or long)? Are both data files ‘tidy’? If you need more info on what that means, have a look here.\n\n\n\nStep 2: Restructuring the ratings data\nWe are going to need to do some data-wrangling before we do any analysis! Specifically, we need the change the ratings data to the long format.\nHere we’ll use the pivot_longer() function (see here or type ?pivot_longer in the Console for more info) to restructure the ratings data from wide to long and store the resulting table as ‘ratings_tidy’.\n\nTASK: Use the code snippet below to restructure the data. Have a look at each line of code (and the comments in green) and check that you understand how it works.\n\n\nratings_tidy &lt;- pivot_longer(\n  data = ratings,    # the data you want to restructure\n  cols = P1:P28,     # columns you want to restructure\n  names_to = \"participant\", # variable name that captures whatever is across the columns\n  # (in this case P1 to P28 for the 28 different participants)\n  values_to = \"rating\") # variable name that captures whatever is in the cells\n  # (in this case numbers for ratings)\n\n\n\nStep 3: Calculate mean trustworthiness rating for each voice\nNow that we have the ratings data into a tidy format, the next step is to calculate the mean rating for each voice. Remember that each voice is identified by the ‘VoiceID’ variable.\n\nTASK: Calculate the mean rating for each voice and store the resulting table in a variable named ‘ratings_mean’.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse group_by() and summarise(). Are you using the tidy data? Also, remember that if there are any missing values (NAs) then na.rm = TRUE would help.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nratings_mean &lt;- ratings_tidy %&gt;% \n  group_by(VoiceID) %&gt;% \n  summarise(mean_rating = mean(rating))\n\n\n\n\n\nStep 4: Join the data together\nOk, before we get ahead of ourselves, in order to perform the regression analysis we need to combine the data from ‘ratings_mean’ (the mean ratings) with ‘acoustics’ (the pitch and dispersion ratings). Also, as we said, we only want to analyse male voices today.\n\nTASK: Join the two tables and keep only the data for the male voices, call the resulting table ‘joined’.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the inner_join() function (making use of the variable that is common across both tables) to join. See here or type ?inner_join in the Console for more info. Use the filter() function to only keep male voices. Remember that the Boolean operator for exactly equal is ==.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\njoined &lt;- ratings_mean %&gt;%\n  inner_join(acoustics, \"VoiceID\") %&gt;% \n  filter(sex == \"M\")\n\n\n\n\n\nStep 5: Spreading the data\nWe are starting to get an understanding of our data and we want to start thinking about the regression. However, the regression would be easier to work with if Pitch and Dispersion were in separate columns. This can be achieved using the pivot_wider() function (see here or type ?pivot_wider in the Console for more info). This is basically the inverse of pivot_longer(). It increases the number of columns and decreases the number of rows.\n\nTASK: Use the code snippet below to spread the data. Have a look at each line of code (and the comments in green) and check that you understand how it works.\n\n\njoined_wide &lt;- joined %&gt;%\n  pivot_wider(\n    names_from = measures, # name of the categorical column to spread\n    values_from = value) # name of the data to spread\n\n\nQUESTION 2 Why do we not need to specify within the pivot_wider() function which data to use?\n\n\n\nStep 6: Visualising the data\nAs always, it is a good idea to visualise your data.\n\nTASK: Now that we have all the variables in one place, make two scatterplots, one of mean trustworthiness rating with dispersion and one for mean trustworthiness rating and pitch.\n\n\n\n\n\n\n\nHint 1\n\n\n\n\n\nFor this you’ll need the ggplot() function together with geom_point() and geom_smooth(). Make sure to give your axes some sensible labels.\n\n\n\n\n\n\n\n\n\nHint 2\n\n\n\n\n\nBelow is a template for the code. Make sure to specify the data frame and the relevant variables.\nggplot(DATA, aes(x = variable X, y = variable Y)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  theme_bw() +\n  labs (y = \"Label for variable Y\")\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nggplot(joined_wide, aes(x = Dispersion, y = mean_rating)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  theme_bw() +\n  labs (y = \"Mean Trustworthiness Rating\")\n\nggplot(joined_wide, aes(x = Pitch, y = mean_rating)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  theme_bw() +\n  labs (y = \"Mean Trustworthiness Rating\")\n\n\n\n\nQUESTION 3 According to the scatterplots, how would you describe the relationships between trustworthiness and dispersion and trustworthiness and pitch in terms of direction and strength? Which one of the two seems stronger?\n\n\n\nStep 7: Conducting and interpreting simple regression\nWith all the variables in place and having gained a better understanding of our data by inspecting the scatterplots, we’re ready now to start building two simple linear regression models:\n\nPredicting trustworthiness mean ratings from Pitch\nPredicting trustworthiness mean ratings from Dispersion\n\n\nTASK: Use the lm() function to run the following two regression models and use the summary() function to look at the output of each model. Store the first model in a table called ‘mod_pitch’ and store the second model in ‘mod_disp’.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nBelow is a template for the code. Make sure to specify the data frame and the relevant variables.\nlm(dv ~ iv, data = my_data)\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nmod_disp &lt;- lm(mean_rating ~ Dispersion, joined_wide)\nmod_disp_sum &lt;- summary(mod_disp)\n\nmod_pitch &lt;- lm(mean_rating ~ Pitch, joined_wide)\nmod_pitch_sum &lt;- summary(mod_pitch)\n\n\n\n\nQUESTION 4 What do you conclude from the output of these models? Which model is significant? Which predictors are significant? How much variance does each model describe?\n\n\n\nStep 8: Conducting and interpreting multiple regression\nNow let’s look at both predictors in the same model. Before we do this, it is sensible to center and standardise the predictors.\nLook at the code below. Can you follow how the predictors are first centered (_c) and then standardised (_z)?\nHere I do this by hand because I think it makes it clearer, even though there are functions that do this in one step (scale()).\n\njoined_wide &lt;- mutate(joined_wide,\n                      Dispersion_c = Dispersion - mean(Dispersion),\n                      Dispersion_z = Dispersion_c / sd(Dispersion_c),\n                      Pitch_c = Pitch - mean(Pitch),\n                      Pitch_z = Pitch_c / sd(Pitch_c))\n\n\nTASK: Now use the centered and standardised data for the multiple regression. Use the lm() function to run a model for predicting trustworthiness mean ratings from Pitch and Dispersion, and store the model in ‘mod_pitchdisp_z’. Use the ‘summary()’ function to look at the output.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nBelow is a template for the code. Make sure to specify the data frame and the relevant variables.\nlm(dv ~ iv1 + iv2, data = my_data)\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nmod_pitchdisp_z &lt;- lm(mean_rating ~ Pitch_z + Dispersion_z, joined_wide)\nmod_pitchdisp_z_sum &lt;- summary(mod_pitchdisp_z)\n\n\n\n\nQUESTION 5 What do you conclude from the output of this model? Is the overall model significant? Which predictors are significant? How much variance does the model describe? Which model would you say is best for predicting ratings of trustworthiness, the Pitch only, the Dispersion only or the Pitch+Dispersion model?\n\n\n\nStep 9: Checking assumptions\nNow that we’ve established which model best fits the data, let’s check whether it meets the assumptions of linearity, normality and homoscedasticity.\n\nTASK: Check the assumptions of linearity, normality and homoscedasticity.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou can use the crPlots() and the qqPlot() functions to check linearity. The shapiro.test() can be used to check normality of the residuals and the residualPlot() and nvcTest() functions to check homoscedasticity of the residuals. These plots are from base R rather than using the ggplot() function. See [here] (https://r4ds.hadley.nz/base-r#plots) for a brief explanation of base R plots and why you might want to use them.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\ncrPlots(mod_pitch)\n\nqqPlot(mod_pitch$residuals) \nshapiro.test(mod_pitch$residuals)\n\nresidualPlot(mod_pitch)\nncvTest(mod_pitch)\n\n\n\n\nQUESTION 6 What do you conclude from the graphs and output? Should we also check for collinearity?\n\n\n\nStep 10: Writing up the results\n\nTASK: Write up the results following APA guidelines.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nThe Purdue writing lab website is helpful for guidance on punctuating statistics. The APA Style 7th Edition Numbers and Statistics Guide is also useful."
  },
  {
    "objectID": "Week11.html#sec-wk11-answers",
    "href": "Week11.html#sec-wk11-answers",
    "title": "1. Recap of the linear model and practising data-wrangling in R",
    "section": "Answers",
    "text": "Answers\nWhen you have completed all of the lab content, you may want to check your answers with our completed version of the script for this week. Remember, looking at this script (studying/revising it) does not replace the process of working through the lab activities, trying them out for yourself, getting stuck, asking questions, finding solutions, adding your own comments, etc. Actively engaging with the material is the way to learn these analysis skills, not by looking at someone else’s completed code…\n\n\nLab activity 1: Interpreting and reporting results\n\nWhat is the outcome or dependent variable? Word reading\nWhat is the predictor or independent variable? Non-word reading\nIs the overall model significant? Yes, F(1,50) = 69.03, p &lt; .001\nHow much variance does the model account for? 58%\nDoes the relationship appear linear? Yes. The dots and the pink line assemble quite closely on the dashed line.\nDo the residuals show normality and homoscedasticity? The qq-plot suggests that the residuals are normally distributed as the dots fall close to the solid blue line and within the range of the dashed blue lines. The Shapiro-Wilk test of normality confirms this (it is not significant). Similarly, the output of the non-constant variance score tests is not significant suggesting that the residuals are homoscedastic.\n\n\n\nLab activity 2: Conducting simple and multiple regression\nYou can download the R-script that includes the relevant code and answers to the questions here: 402_wk11_labAct2_withAnswers.R."
  },
  {
    "objectID": "Week13.html",
    "href": "Week13.html",
    "title": "3. More on interactions",
    "section": "",
    "text": "Interactions are ubiquitous in psychological science, which is why we’ll spend some more time building models that include interaction terms. Last week we modelled well-being as a function of screen-time (a continuous predictor) and biological sex (a categorical predictor) and their interaction. This week we’ll look at interactions between continuous predictors."
  },
  {
    "objectID": "Week13.html#sec-wk13-lectures",
    "href": "Week13.html#sec-wk13-lectures",
    "title": "3. More on interactions",
    "section": "Lectures",
    "text": "Lectures\nThe lecture material for this week follows the recommended chapters in Winter (2020) – see under ‘Reading’ below – and is presented below:\nMore on interactions (~18 min)\n\nSlides Transcript\nIf you need to remind yourself about the why’s and how’s of centering and standardising, please revisit this video. We’ll be using this in the lab activity.\nCentering and standardising (~5 min)\n\nSlides Transcript"
  },
  {
    "objectID": "Week13.html#sec-wk13-reading",
    "href": "Week13.html#sec-wk13-reading",
    "title": "3. More on interactions",
    "section": "Reading",
    "text": "Reading\n\nWinter (2020)\nLink\nChapter 8 explains what interactions are and how to model and interpret them."
  },
  {
    "objectID": "Week13.html#sec-wk13-pre-lab-activities",
    "href": "Week13.html#sec-wk13-pre-lab-activities",
    "title": "3. More on interactions",
    "section": "Pre-lab activities",
    "text": "Pre-lab activities\nAfter having watched the lectures and read the textbook chapters you’ll be in a good position to try these activities. Completing them before you attend your lab session will help you to consolidate your learning and help move through the lab activities more smoothly.\n\nPre-lab activity 1: Cheatsheets\nLast week, we had a look at some of the ‘recipes’ that Posit (the company behind RStudio) provides. If you need a reminder, an overview of all their ‘recipes’ can be found here.\nAnother great resource they provide are the ‘cheatsheets’: one-page overviews of the most important functions in a particular R package/library. There are many and some have been translated into differnt languages. You can access them online, or print them as a pdf to have on hand.\n\nTASK Explore the cheatsheets linked to below. The ones for RStudio IDE, dplyr, and ggplot2 are most relevant to the work we’ve been doing.\n\n\nOverview of all cheatsheets\nCheatsheet for RStudio IDE\nCheatsheet for dplyr\nCheatsheet for ggplot2\n\n\n\nPre-lab activity 2: Getting ready for the lab class\n\nGet your files ready\nDownload the 402_week13_forStudents.zip file and upload it into a new folder in RStudio Server.\n\n\nRemind yourself of how to access and work with the RStudio Server.\n\nSign in to the RStudio Server. Note that when you are not on campus you need to log into the VPN first (look on the portal if you need more information about that).\nCreate a new folder for this week’s work.\nUpload the zip-file to the folder you have created on the RStudio server. Note you can either upload a single file or a zip-file.\n\n\n\n\n\n\n\nIf you have difficulty uploading files to the server\n\n\n\nIf you get error messages when attempting to upload a file or a folder with files to the server, you can try the following steps:\n\nClose the R Studio server, close your browser and start afresh.\nOpen the R Studio server in a different browser.\nFollow a work around where you use code to directly download the file to the server. The code to do that will be available at the start of the lab activity where you need that particular file. The code to download the file you need to complete the quiz is below."
  },
  {
    "objectID": "Week13.html#sec-wk13-lab-activities",
    "href": "Week13.html#sec-wk13-lab-activities",
    "title": "3. More on interactions",
    "section": "Lab activities",
    "text": "Lab activities\nIn this lab, you’ll gain understanding of and practice with:\n\nwhen and why to apply multiple regression to answer questions in psychological science\nconducting multiple regression in R including interaction between continuous predictors\ninterpreting the R output of multiple linear regression (when including an interaction between continuous predictors)\nreporting results for multiple linear regression (when including an interaction between continuous predictors), following APA guidelines\n\n\nBackground\nToday, we’ll be working with a dataset from the following paper: Hamermesh, D. S. and Parker, A. (2005). Beauty in the classroom: instructors’ pulchritude and putative pedagogical productivity. Economics of Education Review, 24(4), 369 – 376.\nThe abstract of their paper is below or see here for the paper itself.\nAbstract: Adjusted for many other determinants, beauty affects earnings; but does it lead directly to the differences in productivity that we believe generate earnings differences? We take a large sample of student instructional ratings for a group of university teachers and acquire six independent measures of their beauty, and a number of other descriptors of them and their classes. Instructors who are viewed as better looking receive higher instructional ratings, with the impact of a move from the 10th to the 90th percentile of beauty being substantial. This impact exists within university departments and even within particular courses, and is larger for male than for female instructors. Disentangling whether this outcome represents productivity or discrimination is, as with the issue generally, probably impossible.\nOur research question: Do professors’ beauty score and age predict how students evaluate their teaching?\nTo complete this lab activity, you can use the R-script (402_wk13_labAct1_template.R) that you downloaded as part of the ‘Pre-lab activities’ as a template. Work through the activity below, adding relevant bits of code to your script as you go along.\n\n\nStep 1: Set up\n\n\n\n\n\n\nSet your working directory\n\n\n\nThe folder you were asked to download under ‘Pre-lab activity 3: Getting ready for the lab class’ contains the data files we’ll need. Make sure you have set your working directory to this folder by right-clicking on it and selecting ‘Set as working directory’.\n\n\n\n\n\n\n\n\nEmpty the R environment\n\n\n\nBefore you do anything else, when starting a new analysis, it is a good idea to empty the R environment. This prevents objects and variables from previous analyses interfering with the current one. To do this, you can click on the little broom icon in the top right of the Environment pane, or you can use rm(list=ls()).\n\n\nBefore we can get started we need to tell R which libraries to use. For this analysis we’ll need broom, car, lsr and tidyverse.\n\nTASK: Load the relevant libraries. If you are unsure how to do that, you can look at the ‘Hint’ below for a clue by expanding it. After that, if you are still unsure, you can view the code by expanding the ‘Code’ section below.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the library() function.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below.\nlibrary(broom)\nlibrary(car)\nlibrary(lsr)\nlibrary(tidyverse)\n\n\n\n\n\n\n\n\n\nIf you couldn’t upload files to the server, do this:\n\n\n\nIf you experienced difficulties with uploading a folder or a file to the server, you can use the code below to directly download the file you need in this lab activity to the server (instead of first downloading it to you computer and then uploading it to the server). Remember that you can copy the code to your clipboard by clicking on the ‘clipboard’ in the top right corner.\n\n\n\ndownload.file(\"https://github.com/mg78/2324_PSYC402/blob/main/data/week13/beauty.csv?raw=true\", destfile = \"beauty.csv\")\n\n\nTASK: Finally, read in the data file (beauty.csv), and familiarise yourself with its structure.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the read_csv() function and the head() function.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below.\nbeauty &lt;- read_csv(\"beauty.csv\")    \nhead(beauty)\n\n\n\nQUESTION 1: Do you notice anything about the name of one of the variables and the name of the data table?\nThe table contains, amongst other things, the following characteristics of the professors\n\n‘beauty’ - beauty score per professor\n‘eval’ - teaching evaluation score per professor\n‘age’ - age of the professor\n\nQUESTION 2: Go back to the research question (see under ‘Background’ above), which of these three variables is the outcome variable? Which ones are the predictors?\n\n\nStep 2: Descriptive statistics and distributions\n\nTASK: Calculate some descriptive statistics for the variables of interest (eval, beauty and age).\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou can use summarise() to calculate the mean, sd, min and max values.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\ndescriptives &lt;- beauty %&gt;% \n  summarise(mean_age = mean(age, na.rm = TRUE),\n            sd_age = sd(age, na.rm = TRUE),\n            min_age = min(age, na.rm = TRUE),\n            max_age = max(age, na.rm = TRUE),\n            mean_eval = mean(eval, na.rm = TRUE),\n            sd_eval = sd(eval, na.rm = TRUE),\n            min_eval = min(eval, na.rm = TRUE),\n            max_eval = max(eval, na.rm = TRUE),\n            mean_beauty = mean(beauty, na.rm = TRUE),\n            sd_beauty = sd(beauty, na.rm = TRUE),\n            min_beauty = min(beauty, na.rm = TRUE),\n            max_beauty = max(beauty, na.rm = TRUE))\n\n\n\nNow that we have the descriptive statistics, let’s get further information about the distribution of the variables by plotting histograms.\n\nTASK: Visualise the distributions of the variables of interest in histograms.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse ggplot() and geom_historgram()\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nggplot(data = beauty, aes(beauty)) +\n  geom_histogram()\n\nggplot(data = beauty, aes(eval)) +\n  geom_histogram()\n\nggplot(data = beauty, aes(age)) +\n  geom_histogram()\n\n\n\n\n\nStep 3: Center and standardise\nAs mentioned before, it will make it easier to interpret regression models with multiple predictors if we center and standardise our predictors. Before we go any further, we’ll do that.\n\nTASK: Center and standardise the predictor variables.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nCentering involves subtracting the mean; standardising involves dividing by the standard deviation.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nbeauty_z &lt;- beauty %&gt;%\n  mutate(age_z = (age - mean(age, na.rm = TRUE)) / sd(age),\n         beauty_z = (beauty - mean(beauty, na.rm = TRUE)) / sd(beauty))\n\n\n\n\n\nStep 4: Scatterplots\nNow let’s have a look at the relationships between variables using scatterplots. To remind yourself of what centering and standardising does, do this for both the raw data and the centered and standardised data.\n\nTASK: Visualise the relationships between the variables of interest in scatterplots.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nCreate six different scatterplots using ggplot() with geom_point() and geom_smooth().\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nggplot(beauty, aes(x = beauty, y = age)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = TRUE) +\n  theme_bw()\n\nggplot(beauty, aes(x = beauty, y = eval)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = TRUE) +\n  theme_bw()\n\nggplot(beauty, aes(x = age, y = eval)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = TRUE) +\n  theme_bw()\n\nggplot(beauty_z, aes(x = beauty_z, y = age_z)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = TRUE) +\n  theme_bw()\n\nggplot(beauty_z, aes(x = beauty_z, y = eval)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = TRUE) +\n  theme_bw()\n\nggplot(beauty_z, aes(x = age_z, y = eval)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = TRUE) +\n  theme_bw()\n\n\n\nQUESTION 3: Can you write an interpretation of the above plots in plain English?\nQUESTION 4: What is the difference between the scatterplots plotting the raw data and the ones plotting the centered and standardised data?\nIt is useful to have a quick look at the bivariate correlations between the variables of interest, before you run a regression model. We can easily generate a correlation matrix for these variables.\n\nTASK: Add the code below to your script and check you understand what each line does.\n\n\nbeauty_matrix &lt;- beauty_z %&gt;%\n  select(eval, age_z, beauty_z) %&gt;% # only keep relevant variables\n  as.data.frame() # tell R it is a specific type of data frame (needed for the correlate() function)\n\npairs(beauty_matrix) # make multiple scatterplots in one go\n\nintercor_results &lt;- correlate(x = beauty_matrix, # our data\n                              test = TRUE, # compute p-values\n                              corr.method = \"pearson\", # run a spearman test \n                              p.adjust.method = \"bonferroni\") # use the bonferroni correction\nintercor_results\n\nAfter you’ve run this code, look at the output in the console. It creates three tables, one with correlation coefficients, one with p-values for these coefficients and one with sample sizes.\n\n\nStep 5: The regression model\nWe’ve looked at descriptive statistics and distributions of variables and also at relations between variables. This has given us a good idea of what the data look like. Now we’ll construct the regression model to predict ‘evaluation score’ as a function of ‘age’ and ‘beauty score’. We’ll do this in two stages. First we’ll construct a model without an interaction term. Then we’ll construct a model that includes an interaction term betweeen the two predictor variables. Don’t forget to use the standardised data for all this.\n\nTASK: Construct a regression model without an interaction term.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the following formula, lm(y ~ x1 + x2, data); go back to the research question for your outcome and predictor variables.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nmod &lt;- lm(eval ~ age_z + beauty_z, data = beauty_z)\n\n\n\n\nTASK: Call and save the summary of your model; then have a look at it.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the summary() function.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nmod_int_summary &lt;- summary(mod_int)\nmod_int_summary\n\n\n\nQUESTION 5: Is the overall model significant?\nQUESTION 6: Are the predictors significant? What does this mean?\n\nTASK: Now create a model that includes an interaction term for the two predictors. Again, use the centered and standardised data.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the following formula, lm(y ~ x1 + x2 + x1:x2, data); go back to the research question for your outcome and predictor variables.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nmod_int &lt;- lm(eval ~ age_z + beauty_z + age_z:beauty_z, data = beauty_z)\nmod_int_summary &lt;- summary(mod_int)\nmod_int_summary\n\n\n\nQUESTION 7: Is the overall model significant?\nQUESTION 8: Have a good look at the coefficients. Can you interpret each one of them in turn and then formulate an overall interpretation?\n\n\n\n\n\n\nHint\n\n\n\n\n\nRemember that after centering and standardising, the meaning of 0 has changed for both predictor variables.\n\n\n\nInterpretation of coefficients in a multiple regression can be facilitated by ‘added variable’ plots.\n\nTASK: Use the function avPlots() to create ‘added variable’ plots.\n\nCreating a scatterplot with our outcome variable on the y-axis and the significant predictor on the x-axis and then plotting our third variable (age) using different colours gives some information. Do you see how high age scores (light blue + 2 SD) seem to be more frequent in the bottom left corner?\n\nTASK: Use the code below to create the plot.\n\n\nggplot(data = beauty_z, aes(x = beauty_z, y = eval, colour = age_z)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = TRUE, colour = 'black') +\n  theme_bw() +\n  labs(x = \"Beauty score\", y = \"Teaching evaluation score\")\n\nBut it might be more useful to plot different regression lines for different values of age. We can do this be transforming age into a categorical variable for plotting purposes. We want to create three categories, based on eye-balling the histogram for age:\n\nyoungest (40 and younger)\naverage (between 41 and 53)\noldest (54 and older).\n\nWe can do this by using the mutate() function, in combination with the cut() function. There is a ‘recipe’ for this on the Posit website:\n\ncut() - group continuous variable into categories - recipe\n\n\nTASK: Read through the recipe mentioned above. Working through the example will be particularly helpful. Write the code to create the categories mentioned above.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nFill in the relevant bits in the code template below:\n  mutate(NEW VARIABLE = cut(\n    CONTINUOUS VARIABLE,\n    breaks = c(DEFINE BREAK POINTS),\n    labels = c(ADD LABELS FOR BREAK POINTS)\n    )\n  )\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nbeauty_z_ageCat &lt;- beauty_z %&gt;%\n  mutate(ageCat = cut(\n    age,\n    breaks = c(0, 40, 54, Inf),\n    labels = c(\"youngest\",\"average\",\"oldest\")\n    )\n  )\n\n\n\nNow let’s create a single plot with three different lines, one for each of the age groups created above.\n\nTASK: Copy the code below to your script and make sure you understand what it does.\n\n\nggplot(data = beauty_z_ageCat, aes(x = beauty_z, y = eval, colour = ageCat)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = TRUE) +\n  theme_bw() +\n  labs(x = \"Beauty score\", y = \"Teaching evaluation score\")\n\nThe line for the oldest participants seems much steeper than for the other two groups, suggesting that the interaction between age and beauty is mostly driven by older participants who have received more extreme beauty scores.\n\n\nStep 6: Checking assumptions\nNow that we’ve fitted a model, let’s check whether it meets the assumptions of linearity, normality and homoscedasticity.\nLinearity Unlike when we did simple regression we can’t use crPlots() to test for linearity when there is an interaction, but we know from looking at the grouped scatterplot that this assumption has been met.\nNormality Normally we would test for normality with a qq-plot and a Shapiro-Wilk test. However, because this dataset is so large, the Shapiro-Wilk is not appropriate (if you try to run the test it will produce a warning telling you that the sample size must be between 3 and 5000). This is because with extremely large sample sizes the Shapiro-Wilk test will find that any deviation from normality is significant. Therefore we should judge normality based upon the qq-plot.\n\nTASK: Create a qq-plot to check the residuals are normally distributed.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the qqPlot() function; mind the capital P.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nqqPlot(mod_int$residuals)\n\n\n\nQUESTION 9: What do you conclude from the qq-plot?\nHomoscedasticity Here we have the same problem as with testing for normality: with such a large sample the ncvTest() will produce a significant result for any deviation from homoscedasticity. So we need to rely on plots again.\nTo check for homoscedasticity we can use plot() from Base R that will produce a bunch of helpful plots (more information [here] (https://www.r-bloggers.com/2016/01/how-to-detect-heteroscedasticity-and-rectify-it/).\n\nTASK: Copy the code below to your script and run it to create the plots\n\n\npar(mfrow=c(2,2))                 # 4 charts in 1 panel\nplot(mod_int)                     # this may take a few seconds to run\n\nQUESTION 10: What do you conclude from the residuals vs leverage plot?\nMulti-collinearity Now let’s check for multi-collinearity using the vif() function. Essentially, this function estimates how much the variance of a coefficient is “inflated” because of linear dependence with other predictors, i.e., that a predictor isn’t actually adding any unique variance to the model, it’s just really strongly related to other predictors. Thankfully, the vif() function is not affected by large samples like the other tests. There are various rules of thumb, but most converge on a VIF of above 2 - 2.5 for any one predictor being problematic.\n\nTASK: Use the vif() function to test for multi-collinearity.\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nvif(mod_int)   \n\n\n\nQUESTION 11: Do any of the predictors show evidence of multi-collinearity?\nFinally, we need to write up the results.\nQUESTION 12: Can you write up the results of the regression analysis following APA guidelines?\n\n\n\n\n\n\nHint\n\n\n\n\n\nDon’t forget to mention and interpret the interaction effect."
  },
  {
    "objectID": "Week13.html#sec-wk13-answers",
    "href": "Week13.html#sec-wk13-answers",
    "title": "3. More on interactions",
    "section": "Answers",
    "text": "Answers\nWhen you have completed all of the lab content, you may want to check your answers with our completed version of the script for this week. Remember, looking at this script (studying/revising it) does not replace the process of working through the lab activities, trying them out for yourself, getting stuck, asking questions, finding solutions, adding your own comments, etc. Actively engaging with the material is the way to learn these analysis skills, not by looking at someone else’s completed code…\n\nYou can download the R-script that includes the relevant code here: 402_wk13_labAct1_withAnswers.R.\n\nDo you notice anything about the name of one of the variables and the name of the data table? Both the data table and one of the variables are called ‘beauty’. Not a problem, as such as long as you don’t get confused.\nGo back to the research question (see under ‘Background’ above), which of these three variables is the outcome variable? Which ones are the predictors? The research question is ‘Do professors’ beauty score and age predict how students evaluate their teaching?’ From this we can deduct that the outcome variable is teaching evaluation score and that the predictors are age and beauty score.\nCan you write an interpretation of the above plots in plain English? A moderate negative association seems present between beauty score and age: with increasing age, beauty score decreases. A moderate positive association seems present between beauty score and teaching evaluation: professors with higher beauty scores also receive higher teaching evaluations. Not much of a association seems present between age and teaching evaluation (the line is pretty horizontal).\nWhat is the difference between the scatterplots plotting the raw data and the ones plotting the centered and standardised data? The units of the x-axis have changed from years (for age) and scores (for beauty) to standard units, with zero in the middle.\nIs the overall model significant? Yes, F(2, 460) = 8.53, p = .0002\nAre the predictors significant? What does this mean? The beauty score significantly predicts teaching evaluation score, but age does not. Professors with higher beauty scores, received better teaching evaluations.\nIs the overall model significant? Yes, F(3, 459) = 9.32, p = 5.451e-06\nHave a good look at the coefficients. Can you interpret each one of them in turn and then formulate an overall interpretation? HINT: Remember that after centering and standardising, the meaning of 0 has changed for both predictor variables. The intercept is predicted teaching evaluation score for a professor with average age and average beauty score. The slope of ‘age’ is positive; this means that for higher age, teaching evaluation scores were better. However the coefficient is not significant, therefore has little predictive power.The slope of ‘beauty’ is positive; this means that with higher beauty score, professors receive higher teaching evaluations. This predictor is significant. The slope for the interaction is also positive. This can be read as follows: When age and beauty both increase, teaching evaluation score also increases. The interaction is significant.\nWhat do you conclude from the qq-plot? The residuals are mostly normally distributed. At the top right (quantile + 3), there are some values that don’t quite look normally distributed, this is probably due to fewer data points being available in the highest age bracket. Have a look at a histogram for age. There are a few individuals well above the retirement age, but clearly a lot fewer than in younger age brackets. This basically means that the model does not do a particularly good job for predicting evaluation score at high values of age. As retirement age is quite a natural point to limit the data, you could run the model again, only including people below retirement age, this should give you better behaving residuals. Ideally, you’d pre-register a decision such as this. If you didn’t do this prior to data collection, you could still limit the age range included in the final model, but you would need to be transparent in your reporting.\nWhat do you conclude from the residuals vs leverage plot? The residuals vs leverage plot shows a flat red line so, whilst it isn’t perfect, we can assume that with regression is still an appropriate analysis.\nDo any of the predictors show evidence of multi-collinearity? No\nCan you write up the results of the regression analysis following APA guidelines? The results of the regression indicated that the model significantly predicted teaching evaluation scores (F(3, 459) = 9.316, p &lt; .001, adjusted R^2 = 0.05), accounting for 5% of the variance. A professor’s beauty score was a significant positive predictor of teaching evaluation score (\\(\\beta\\) = 0.12, p &lt; .001). This effect was moderated by a significant positive interaction between beauty score and age (\\(\\beta\\) = 0.08, p &lt; .001), suggesting that when age and beauty score both increased, teaching evaluation score also increased."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Analysing and Interpreting Psychological Data II",
    "section": "",
    "text": "Welcome\nWelcome to PSYC402!\nThis module builds on the knowledge and skills acquired in Statistics for Psychologists 1 (PSYC401). You will continue to practise data handling, data processing and data visualisation, using R and R Studio. In addition, you will extend your knowledge of the general linear model and learn how to adapt it when working with different types of data. Of course you’ll also learn how to implement those methods in R and R Studio.\nThis page gives you access to all the materials that you will need. You will have timetabled lab classes during which you are expected to work through a series of exercises to practise that week’s material. Before you come to your lab session, you should watch the lectures for that week, read the relevant book chapter and complete the pre-lab activities.\n\n\nAsking for help\nWe have carefully prepared and refined the lab materials in this course over several years, and we feel that the pace of the materials is just right for our students. Some students will complete them more quickly, and others more slowly - both of these scenarios are absolutely fine. You should work at the pace that suits you best, making sure you understand the materials before you move forward.\nIt is fairly inevitable that you will get stuck on the lab materials in this module at some point. This might be in Week 11, Week 12, or later. When you do, it’s important you reach out for help:\n\nAsk your friends on your table. We’ve designed this teaching space to help collaborative work. You are encouraged to work with other students. Make sure you ask others to explain how they’ve solved an exercise. Make sure you help out others where you can. Always make sure you understand the code and the exercise; don’t simply be satisfied that you’ve got the right answer.\nAsk a GTA or Lecturer. Our teaching staff is there to help you. There are no “stupid questions” in statistics, so just ask the GTA or the lecturer any question about what you’re doing.\nAsk on the Discussion Forum. On the PSYC402 moodle page you will find a Discussion Forum. This is a great way to ask a question outside of the lab sessions. It might seem scary to ask a question in the forum, but please don’t be afraid to do this. If you have a question, you can bet other students also have the same question! So by asking the question on the forum, you help out many more people on the module. A friendly GTA or Lecturer will be along to answer the question as soon as possible (we aim for within 48 hours during the working week).\nAsk on the module Q & A session. Each week we hold a “Q&A” online session where we will try and resolve any general queries and problems. It’s an ideal time to discuss things that students are struggling with or confused about, and can share ideas and answers. You can ask on the discussion forum above and then we might be able to pick up the issues and discuss them, but also you can ask in the session itself.\n\n\n\nCourse Contacts\n\n\n\n\nEmail Address\n\n\n\n\nMargriet Groen\nm.groen at lancaster dot ac dot uk\n\n\nRob Davies\nr.davies1 at lancaster dot ac dot uk\n\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Week12.html",
    "href": "Week12.html",
    "title": "2. Categorical predictors",
    "section": "",
    "text": "So far, all the predictors in the models we’ve looked at were continuous variables. What if you wanted to know whether a response differed between two or more discrete groups? Hang on, you might say, that sounds like doing an ANOVA. True, you might have used ANOVA to assess whether group means differed in previous stats courses. ANOVAs—to some degree—are just a special type of regression where you have categorical predictors. This week we’ll look at how to model responses as a function of categorical predictors and we’ll combine categorical predictors to model how a predictor might affect the outcome variable differently across two different groups. For example, we might be interested in whether the amount of time adolescents use digital devices (screen-time) predicts their well-being. Additionally, we might want to know whether well-being is different for adolescent boys and girls and whether the relationship between screen-time and well-being differs for these two groups. By fitting a regression model in which we combine a continuous (screen-time) and a categorical (sex) predictor, we can do exactly that. We’ll be working on that in the lab."
  },
  {
    "objectID": "Week12.html#sec-wk12-lectures",
    "href": "Week12.html#sec-wk12-lectures",
    "title": "2. Categorical predictors",
    "section": "Lectures",
    "text": "Lectures\nThe lecture material for this week follows the recommended chapters in Winter (2020) – see under ‘Reading’ below – and is presented in two parts. The videos have captions, in case you find that helpful. You can download the slides and the transcripts by clicking on the links below the videos.\n\nCategorical predictors (~17 min)\n\n\nSlides Transcript\n\nInteractions (~18 min)\n\n\nSlides Transcript\nIf you are (relatively) new to using R and RStudio and not yet confident in using various functions from the dplyr package, the video below will be useful:\n\nData wrangling with dplyr (~10 minutes) Watch this part before you complete the pre-lab activities and before you attend the lab session.\n\n\nSlides Transcript"
  },
  {
    "objectID": "Week12.html#sec-wk12-reading",
    "href": "Week12.html#sec-wk12-reading",
    "title": "2. Categorical predictors",
    "section": "Reading",
    "text": "Reading\n\nBlogpost by Professor Dorothy Bishop\nIn this very short blogpost Professor Dorothy Bishop explains the links between ANOVA and Regression.\n\n\nWinter (2020)\nLink\nChapter 7 provides an excellent overview of using categorical predictors in regression models and explains how this is implemented in R.\nChapter 8 explains what interactions are and how to model and interpret them."
  },
  {
    "objectID": "Week12.html#sec-wk12-pre-labactivities",
    "href": "Week12.html#sec-wk12-pre-labactivities",
    "title": "2. Categorical predictors",
    "section": "Pre-lab activities",
    "text": "Pre-lab activities\nAfter having watched the lectures and read the textbook chapters you’ll be in a good position to try these activities. Completing them before you attend your lab session will help you to consolidate your learning and help move through the lab activities more smoothly.\n\nPre-lab activity 1: Data-wrangling in R\nData comes in lots of different formats. One of the most common formats is that of a two-dimensional table (the two dimensions being rows and columns). Usually, each row stands for a separate observation (e.g. a participant), and each column stands for a different variable (e.g. a response, category, or group). A key benefit of tabular data is that it allows you to store different types of data-numerical measurements, alphanumeric labels, categorical descriptors-all in one place.\nIt may surprise you to learn that scientists actually spend far more of time cleaning and preparing their data than they spend actually analysing it. This means completing tasks such as cleaning up bad values, changing the structure of tables, merging information stored in separate tables, reducing the data down to a subset of observations, and producing data summaries. Some have estimated that up to 80% of time spent on data analysis involves such data preparation tasks (Dasu & Johnson, 2003)!\nMany people seem to operate under the assumption that the only option for data cleaning is the painstaking and time-consuming cutting and pasting of data within a spreadsheet program like Excel. We have witnessed students and colleagues waste days, weeks, and even months manually transforming their data in Excel, cutting, copying, and pasting data. Fixing up your data by hand is not only a terrible use of your time, but it is error-prone and not reproducible. Additionally, in this age where we can easily collect massive datasets online, you will not be able to organise, clean, and prepare these by hand.\nIn short, you will not thrive as a psychologist if you do not learn some key data wrangling skills. Although every dataset presents unique challenges, there are some systematic principles you should follow that will make your analyses easier, less error-prone, more efficient, and more reproducible.\nSome of the functions you’ll need in this week’s lab activity are listed below. You’ve used these functions before, but the following ‘recipes’ summarise what each one does and how to use it.\n\nTASK Have a look at each ‘recipe’ and read through it. Try to understand each step.\n\n\n\n\n\n\n\nRecipes - How to use them\n\n\n\nEach ‘recipe’ has the same structure.\n\nFirst, it summarises what it is that you want to achieve when using that specific function. In the case of select() it says “You want to extract specific columns from a data frame and return them as a new, smaller data frame.”\nThen, it outlines a number of steps that you need to carry out when using this function. For select() it outlines 2 steps: 1. Pass the dataframe to the function. 2. List the column(s) to return.\nFinally, there is an example talks you through using the function with some data. For select() it uses an example with data on the weather.\nAdditional information appears in extra boxes with a light-bulb icon. If you find those confusing, don’t worry about them at this stage.\n\n\n\nData wrangling:\n\nfilter() - extract observations (rows) - recipe\nmutate() - create a new variable (column) - recipe\ngroup_by() - organise the observations into groups - recipe\nsummarise() - compute summary statistics - recipe\n\nVisualisation:\n\ngeom_histogram() - draw a histogram - recipe\ngeom_line() - draw a line chart - recipe\n\nThe more you practise coding in R, the easier it will become.\n\n\n\n\n\n\nThe many ‘dialects’ of the R programming language\n\n\n\nPlease note that there are often different ways to do the same or similar things in R. This means you might encounter slightly different functions or styles of coding in different materials. This is not something to worry about. Just make sure you’re clear on what a bit of code achieves and choose the function/style that you feel most comfortable with.\n\n\n\n\nPre-lab activity 2: Getting ready for the lab class\n\nGet your files ready\nDownload the 402_week12_forStudents.zip file.\n\n\nRemind yourself of how to access and work with the RStudio Server.\n\nSign in to the RStudio Server. Note that when you are not on campus you need to log into the VPN first (look on the portal if you need more information about that).\nCreate a new folder for this week’s work.\nUpload the zip-file to the folder you have created on the RStudio server. Note you can either upload a single file or a zip-file.\n\n\n\n\n\n\n\nIf you have difficulty uploading files to the server\n\n\n\nIf you get error messages when attempting to upload a file or a folder with files to the server, you can try the following steps:\n\nClose the R Studio server, close your browser and start afresh.\nOpen the R Studio server in a different browser.\nFollow a work around where you use code to directly download the file to the server. The code to do that will be available at the start of the lab activity where you need that particular file. The code to download the file you need to complete the quiz is below."
  },
  {
    "objectID": "Week12.html#sec-wk12-labactivities",
    "href": "Week12.html#sec-wk12-labactivities",
    "title": "2. Categorical predictors",
    "section": "Lab activities",
    "text": "Lab activities\nIn this lab, you’ll gain understanding of and practice with:\n\nwhen and why to apply multiple regression to answer questions in psychological science\nconducting multiple regression in R when combining continuous and categorical predictors\ninterpreting the R output of multiple linear regression (when combining continuous and categorical predictors)\nreporting results for multiple linear regression (when combining continuous and categorical predictors), following APA guidelines\n\n\nLab activity 1: Combining a continuous and a categorical predictor in a regression model\n\nBackground: Smartphone screen-time and well-being\nThere is currently much debate (and hype) surrounding smartphones and their effects on well-being, especially with regard to children and teenagers. We’ll be looking at data from this recent study of English adolescents: Przybylski, A. & Weinstein, N. (2017). A Large-Scale Test of the Goldilocks Hypothesis. Psychological Science, 28, 204–215.\nThis was a large-scale study that found support for the “Goldilocks” hypothesis among adolescents: that there is a “just right” amount of screen-time, such that any amount more or less than this amount is associated with lower well-being. This was a huge survey study with data containing responses from over 120,000 participants! Fortunately, the authors made the data from this study openly available, which allows us to dig deeper into their results. And the question we want to expand on in this lab is whether the relationship between screen-time and well-being depends on the partcipant’s (self-reported) sex. In other words, our research question is: Does screen-time have a bigger impact on boys or girls, or is it the same for both?\nThe dependent measure used in the study was the Warwick-Edinburgh Mental Well-Being Scale (WEMWBS). This is a 14-item scale with 5 response categories, summed together to form a single score ranging from 14-70.\nOn Przybylski & Weinstein’s page for this study on the Open Science Framework, you can find the participant survey, which asks a large number of additional questions (see page 14 for the WEMWBS questions and pages 4-5 for the questions about screen-time). Within the same page you can also find the raw data, which some of you might want to consider using for your research report.\nHowever, for the purpose of this lab, you will be using local pre-processed copies of the data (participant_info.csv, screen_time.csv and `wellbeing.csv, which you downloaded as part of the ‘Pre-lab activities’.\nPrzybylski and Weinstein looked at multiple measures of screen-time, but again for the interests of this lab we will be focusing on smartphone use, but do feel free to expand your skills after by looking at different definitions of screen-time. Overall, Przybylski and Weinstein suggested that decrements in well-being started to appear when respondents reported more than one hour of daily smartphone use. So, bringing it back to our additional variable of sex, our research question is now: Does the negative association between hours of smartphone use and well-being (beyond the one-hour point) differ for boys and girls?\nLet’s think about this in terms of the variables. We have:\n\na continuous outcome variable: well-being;\na continuous∗ predictor variable: screen-time;\na categorical predictor variable: sex.\n\nPlease note that well-being and screen-time are technically only quasi-continuous inasmuch as that only discrete values are possible. However, there are a sufficient number of discrete categories in our data that we can treat the data as effectively continuous.\nNow, in terms of analysis, what we are effectively trying to do is to estimate two slopes relating screen-time to well-being, one for adolescent girls and one for adolescent boys, and then statistically compare these slopes. Sort of like running a correlation for boys, a correlation for girls, and comparing the two. Or alternatively, where you would run a regression (to estimate the slopes) but also one where you would need a t-test (to compare two groups). But the expressive power of regression allows us to do this all within a single model. Again, as we have seen building up to this lab, an independent groups t-test is just a special case of ordinary regression with a single categorical predictor; ANOVA is just a special case of regression where all predictors are categorical. But remember, although we can express any ANOVA design using regression, the converse is not true: we cannot express every regression design in ANOVA. As such people like regression, and the general linear model, as it allows us to have any combination of continuous and categorical predictors in the model. The only inconvenience with running ANOVA models as regression models is that you have to take care in how you numerically code the categorical predictors. We will use an approach called deviation coding which we will look at today later in this lab.\nTo complete this lab activity, you can use the R-script (402_wk12_labAct1_template.R) that you downloaded as part of the ‘Pre-lab activities’ as a template. Work through the activity below, adding relevant bits of code to your script as you go along.\n\n\nStep 1: Background and set up\n\n\n\n\n\n\nSet your working directory\n\n\n\nThe folder you were asked to download under ‘Pre-lab activity 3: Getting ready for the lab class’ contains the data files we’ll need. Make sure you have set your working directory to this folder by right-clicking on it and selecting ‘Set as working directory’.\n\n\n\n\n\n\n\n\nEmpty the R environment\n\n\n\nBefore you do anything else, when starting a new analysis, it is a good idea to empty the R environment. This prevents objects and variables from previous analyses interfering with the current one. To do this, you can click on the little broom icon in the top right of the Environment pane, or you can use rm(list=ls()).\n\n\nBefore we can get started we need to tell R which libraries to use. For this analysis we’ll need broom, car and tidyverse.\n\nTASK: Load the relevant libraries. If you are unsure how to do that, you can look at the ‘Hint’ below for a clue by expanding it. After that, if you are still unsure, you can view the code by expanding the ‘Code’ section below.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the library() function.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below.\nlibrary(broom)\nlibrary(car)\nlibrary(tidyverse)\n\n\n\n\n\n\n\n\n\nIf you couldn’t upload files to the server, do this:\n\n\n\nIf you experienced difficulties with uploading a folder or a file to the server, you can use the code below to directly download the file you need in this lab activity to the server (instead of first downloading it to you computer and then uploading it to the server). Remember that you can copy the code to your clipboard by clicking on the ‘clipboard’ in the top right corner.\n\n\n\ndownload.file(\"https://github.com/mg78/2324_PSYC402/blob/main/data/week12/participant_info.csv?raw=true\", destfile = \"participant_info.csv\")\n\n\ndownload.file(\"https://github.com/mg78/2324_PSYC402/blob/main/data/week12/screen_time.csv?raw=true\", destfile = \"screen_time.csv\")\n\n\ndownload.file(\"https://github.com/mg78/2324_PSYC402/blob/main/data/week12/wellbeing.csv?raw=true\", destfile = \"wellbeing.csv\")\n\n\nTASK: Finally, read in the three data files; call the participant info pinfo; call the screen_time data screen and the well-being data wellbeing.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the read_csv() function.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below.\npinfo &lt;- read_csv(\"participant_info.csv\")                                   \nscreen &lt;- read_csv(\"screen_time.csv\")\nwellbeing &lt;- read_csv(\"wellbeing.csv\")\n\n\n\n\n\nStep 2: Checking the formatting\nGiven our research question and the information you have about the scores, provided above under ‘Background’ and from the OSF-webpage, is the data ready for use?\n\nTASK: Add code to look at the first few lines of each data frame.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the head() function (or tail() function).\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below:\nhead(pinfo)                                  # Look at the data frames\nhead(screen)\nhead(wellbeing)\n\n\n\n\nQUESTION 2a: In which table is the variable corresponding to sex located and what is this variable called?\n\nThe ‘source and analysis code.sps’ file in the ‘Data and Code’ section on the OSF-webpage tells us how they coded the sex variable: 0 = female indicator and 1 = male indicator. It is worth exploring the OSF-webpage, to get used to foraging other files for these kinds of information, as they are not always clearly explained in a codebook or README. file.\n\nTASK: For ease, lets recode the sex variable to reflect word labels of ‘female’ and ‘male’. This doesn’t change the order: R will still see female as 0, and male as 1 because female occurs before male in the alphabet. Add the code below to your script to do this. Don’t forget to run it as well.\n\n\npinfo$sex &lt;- ifelse(pinfo$sex == 1, \"male\", \"female\")\nhead(pinfo)\n\n\nQUESTION 2b: In what format is the well-being data (long or wide)? On how many participants does it include observations? And on how many items for each participant?\n\n\nQUESTION 2c: What is the name of the variable that identifies individual participants in this dataset? It is important to work this out as this variable will allow us to link information across the three data files.\n\n\n\nStep 3: Data preparation - Aggregating the total well-being scores\nWe need to sum the 14 items of the well-being scale for each participant to create one well-being score per participant.\n\nTASK: To create one well-being score per participant, add code to the script to do the following: first, transform the well-being data frame from wide to long (using pivot_longer()); then, use group_by() to get scores for each participant and finally use summarise() to calculate a total well-being score, calling the new variable tot_wellbeing. Save all of this to an object called wb_tot.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nBelow is a code template. Make sure to add the relevant sections.\nwb_tot &lt;- DATA %&gt;%\n  pivot_longer(-Serial, names_to = \"\", values_to = \"\") %&gt;%\n  group_by(?) %&gt;%\n  summarise(tot_wellbeing = sum(?))\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nwb_tot &lt;- wellbeing %&gt;%\n  pivot_longer(-Serial, names_to = \"question\", values_to = \"score\") %&gt;%\n  group_by(Serial) %&gt;%\n  summarise(tot_wellbeing = sum(score))\n\n\n\nIt is useful to calculate some descriptive statistics for the new variable tot_wellbeing.\n\nTASK: Calculate some descriptive statistics for tot_wellbeing.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse summarise() to calculate the mean, standard deviation, minimum and maximum values.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nwb_tot %&gt;% summarise(mean = mean(tot_wellbeing),\n                     sd = sd(tot_wellbeing),\n                     min = min(tot_wellbeing), \n                     max = max(tot_wellbeing))\n\n\n\nFinally, let’s get an idea of the distribution of the new variable tot_wellbeing.\n\nTASK: Visualise the distribution in a histogram.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse ggplot() and geom_historgram().\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nggplot(wb_tot, aes(tot_wellbeing)) +\n  geom_histogram() \n\n\n\n\nQUESTION 3a: Is the distribution of well-being scores symmetrical, negatively skewed or positively skewed?\n\n\n\nStep 4: Data preparation - Transforming screen time data\nGreat, so we have the well-being scores sorted out, we now need to think about the screen-time usage data and whether it is being used on a weekday or a weekend. As always, to get an idea of the data, it is often very useful to visualise the variables before proceeding with the analysis.\nBefore we can do this, we’ll need to tidy these data up. Have another look at the screen data by using the head() function. You’ll see that we have Serial in the first column (this is good), but in the following eight columns, we have columns for each type of activity (Comph, Comp, Smart, Watch) and the part of the week it took place (we and wk) combined. Instead, to be able to work with the data, we need two columns: one for the type of activity (we’ll call it variable) and one for the part of the week (we’ll call it day).\nA second issue is that we need to alter the abbreviations Comph, Comp, Smart and Watch to reflect more descriptive text for each in plots.\nBelow are two chunks of code that represent these steps. In the next tasks you’ll practise with taking a set of piped commands apart. The purpose of this is to get you used to “parsing” the code at the right places so that when you see piped commands in other people’s code, you know how to break it down and find the relevant parts that you can use.\n\nTASK: In the code chunk below we use the separate() function to split the character strings already in the dataset. You know that with piped commands, there are chunks of code. Run the code first in its entirety and then pull each line apart to see how each function works on the data. Write a descriptive sentence for each function’s role in the command. Don’t forget to copy the chunk to your script and run it.\n\n\nscreen_long &lt;- screen %&gt;%\n  pivot_longer(-Serial, names_to = \"var\", values_to = \"hours\") %&gt;%\n  separate(var, c(\"variable\", \"day\"), \"_\")\n\n\nTASK: In the next code chunk we use the dplyr::recode() function with mutate() to relabel the separated names into understandable names that will be clear in plots. Again, run the code first in its entirety and then pull each line apart to see how each function works on the data. Write a descriptive sentence for each function’s role in the command. Don’t forget to copy the chunk to your script and run it.\n\n\nscreen2 &lt;- screen_long %&gt;%\n  mutate(variable = dplyr::recode(variable,\n                                  \"Watch\" = \"Watching TV\",\n                                  \"Comp\" = \"Playing Video Games\",\n                                  \"Comph\" = \"Using Computers\",\n                                  \"Smart\" = \"Using Smartphone\"),\n         day = dplyr::recode(day,\n                             \"wk\" = \"Weekday\",\n                             \"we\" = \"Weekend\"))\n\n\n\n\n\n\n\nTip\n\n\n\nThe code above has a new feature: the dplyr::recode part. This syntax – using the double colon – happens when there are many versions of a function with the same name. You can imagine that a function called ‘recode’ is immensely useful at the data wrangling stage of analysis. By using the name of the package, a double set of colons, followed by a function name, you are ensuring that R uses a particular version of the function, at that point only. This avoids having two or more packages loaded in your environment that sometimes do not play nicely together!\n\n\nTo be able to monitor that your code is performing as you want it to, you need to have in your mind an idea of how the data should look at the end of a code chunk. So stop a moment and be clear, discuss with your lab-mates if you feel like it and answer the following question.\n\nQUESTION 4a: What are the variables and the levels or conditions within each variable of screen2?\n\n\nTASK:Now join wb_tot and screen_2 by participant and then group by the variables ‘variable’, ‘day’ and ‘hours’ and then calculate a ‘mean_wellbeing’ variable for each of the grouped levels. Save it in an object called ‘dat_means’.\n\n\n\n\n\n\n\nHint 1\n\n\n\n\n\nWrite separate lines of code for each action and then, when you know each of them works, reformat them as a piped command. You’ll need inner_join(), group_by() and summarise().\n\n\n\n\n\n\n\n\n\nHint 2\n\n\n\n\n\nBelow templates for separate lines of code for each action. You’ll need to replace the names of relevant data frames and variables.\njoined &lt;- inner_join(data1, data2, by=)\ngrouped &lt;- group_by(data, var1, var2, var3)\nmeans &lt;- summarise(data, mean = mean(variable))\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nBelow the code for a piped command.\ndat_means &lt;- inner_join(wb_tot, screen2, \"Serial\") %&gt;%\n  group_by(variable, day, hours) %&gt;%\n  summarise(mean_wellbeing = mean(tot_wellbeing))\n\n\n\n\nTASK: Now check that you have an object that is 72 observations of 4 variables. You should have a mean wellbeing score for every level of the hours, over weekdays and weekends for each level of the four types of screen time (4 x 2 x 9)\n\nNext, it is a good idea to visualise the mean well-being data as function of hours of screen-time for the different days (weekday vs. weekend) and types of screen (playing video games, using computers, using smartphone and watching tv). This is quite a complex graph. We’ll go through creating it step-by-step, but let’s first look at the end result:\n\nOk, that’s what we are working towards.\n\nTASK: Below, a chunk of code is presented. It is your task to fill in the x and y variables.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nGo back to the research question - which variable is for the x axis and for the y axis?\n\n\n\n\nggplot(dat_means, aes(x = , y = )) +\n  geom_line() +\n  geom_point() +\n  theme_bw()\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nggplot(dat_means, aes(x = hours, y = mean_wellbeing,)) +\n  geom_line() +\n  geom_point() +\n  theme_bw()\n\n\n\nQUESTION 4b: What research question does this plot describe? Is it appropriate for the levels within the data?\n\nTASK: Now, let’s add a different linetype for each day (weekday vs. weekend). Fill in the blanks in the code below.\n\n\nggplot(dat_means, aes(x = , y = , linetype = )) +\n  geom_line() +\n  geom_point() +\n  theme_bw()\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nggplot(dat_means, aes(x = hours, y = mean_wellbeing, linetype = day)) +\n  geom_line() +\n  geom_point() +\n  theme_bw()\n\n\n\nQUESTION 4c: What research question does this plot describe? Is it appropriate for the levels within the data?\nStill not quite there.\n\nTASK: Fill in the blanks (for x, y and linetype) as before. Now have a good look at the code below. What has changed? Copy the code to your script and run it. Then, for each line write a sentence as a comment to describe its effect on the plot.\n\n\nggplot(dat_means, aes(x = , y = , linetype = )) +\n  geom_line() +\n  geom_point() +\n  facet_wrap(~variable, nrow = 2) +\n  theme_bw()\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nggplot(dat_means, aes(hours, mean_wellbeing, linetype = day)) + # plot 'hours' on the x-axis, 'mean_wellbeing' on the y-axis and use a different type of line for the levels of 'day'\n  geom_line() + # add a line\n  geom_point() + # add point data\n  facet_wrap(~variable, nrow = 2) + # plot separate plots for each level of 'variable'\n  theme_bw() # use the 'black and white' theme\n\n\n\nWe add the facet_wrap() function here. You can check the ?facet_wrap() help page for more information.\nQUESTION 4d: c. What does the facet_wrap() function do? Is this plot appropriate for the levels in the data?\n\n\nStep 5: Calculating mean hours per day for smartphone use, for each participant\nAs mentioned at the beginning, in today’s lab we’ll focus on smartphone use. So looking at the bottom left of the figure we could suggest that smartphone use of more than 1 hour per day is associated with increasingly negative well-being the longer screen time people have. This looks to be a similar effect for Weekdays and Weekends, though perhaps overall well-being in Weekdays is marginally lower than in Weekends (the line for Weekday is lower on the y-axis than Weekends). This makes some sense as people tend to be happier on Weekends!\n\nTASK: Below is a set of comments that describe what the chunk of code that you need to write next does:\n\n\n\n#use ‘screen2’\n#and then filter out the observations for ‘Using Smartphone’,\n#and then group together each participant,\n#and then summarise the mean hours calling it ‘hours_per_day’,\n#save it in an object called ‘smarttot’\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nBelow is a template for the code you need. Try to fill in the relevant bits:\nNEW_OBJECT &lt;- DATA %&gt;%\n  filter(variable == \"?\") %&gt;%\n  group_by(VARIABLE) %&gt;%\n  summarise(new_measure = mean(VARIABLE))\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below:\nsmarttot &lt;- screen2 %&gt;% # use 'screen2'\n  filter(variable == \"Using Smartphone\") %&gt;% # filter out the observations for 'Using Smartphone'\n  group_by(Serial) %&gt;% # group together each participant\n  summarise(hours_per_day = mean(hours)) #summarise the mean hours calling it 'hours_per_day'\n\n\n\n\nTASK: Now let’s do it the other way around. Run the code below. Have a look at the structure of ‘smart_wb’.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou can use the str() function.\n\n\n\n\nsmart_wb &lt;- smarttot %&gt;%\n  filter(hours_per_day &gt; 1) %&gt;%\n  inner_join(wb_tot, \"Serial\") %&gt;%\n  inner_join(pinfo, \"Serial\") %&gt;%\n  mutate(sex = as.factor(sex))\n\n\nQUESTION 5a: What does the code do? Write a short paragraph, using the phrase “and then” to represent the pipes.\n\n\n\nStep 6: More visualisation\nWe are now using only one small part of the data - smartphone use and its relationship with well-being over different durations of time. Before formally testing our research question, we can visualise the data and enquire about sex differences on the same plot - run each chunk of code below:\n\nTASK To further group the data, copy the code below to your script and run it. Look at the ‘smart_wb_gen’ dataframe. What has the code above done? Write a couple of sentences of description.\n\n\nsmart_wb_gen &lt;- smart_wb %&gt;%\n  group_by(hours_per_day, sex) %&gt;%\n  summarise(mean_wellbeing = mean(tot_wellbeing))\n\n\nTASK: Let’s visualise these data.\n\n\nggplot(smart_wb_gen, aes(hours_per_day, mean_wellbeing, color = sex)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  scale_color_discrete(name = \"Sex\", labels = c(\"Girls\", \"Boys\"))+\n  scale_x_continuous(name = \"Total hours smartphone use\") +\n  scale_y_continuous(name = \"Mean well-being score\") +\n  theme_bw()\n\n\nQUESTION 6a: Write an interpretation of the above plot in plain English.\n\n\n\nStep 7: The regression model\nIn the steps 2 to 6 we’ve covered some pretty heavy-lifting data-wrangling. As it is so often the case that something like this is needed when working with real data, ti is really important to practise this. However, to ensure you also spend time on fitting the regression model and interpreting the output, you can choose to use the data-file smart_wb.csv to get started with that. It contains the data in a format that is the result of all the data-wrangling we did in steps 2 to 6. So, download the smart_sb.csv data-file, put it in the folder that is your working directory and you’re all set for running the regression model.\n\n\n\n\n\n\nIf you couldn’t upload files to the server, do this:\n\n\n\nIf you experienced difficulties with uploading a folder or a file to the server, you can use the code below to directly download the file you need in this lab activity to the server (instead of first downloading it to you computer and then uploading it to the server). Remember that you can copy the code to your clipboard by clicking on the ‘clipboard’ in the top right corner.\n\n\n\ndownload.file(\"https://github.com/mg78/2324_PSYC402/blob/main/data/week12/smart_wb.csv?raw=true\", destfile = \"smart_wb.csv\")\n\n\nTASK: Let’s run the regression. Write code in your script in which you call your output ‘mod’, and use the data ‘smart_wb’ using the following formula, lm(y ~ x1 + x2 + x1:x2, data) to construct your regression model. Go back to the research question for your outcome and two predictor variables.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the following template:\nmod &lt;- lm(y ~ x1 + x2 + x1:x2, data)\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nmod &lt;- lm(tot_wellbeing ~ hours_per_day + sex + hours_per_day:sex, smart_wb)\n\n\n\n\nTASK: Call and save the summary of your model as ‘mod_summary’; then have a look at it.\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nmod_summary &lt;- summary(mod)\nmod_summary\n\n\n\nLet’s first look at the model as a whole:\n\nQUESTION 7a: What is the p-value for the overall model? Is it significant? What does this mean?\n\n\nQUESTION 7b: To two decimal places, what percentage of the variance in well-being scores does the overall model explain?\n\nNow, lets look at the coefficients of our predictors:\n\nQUESTION 7c: Are the main effects of smartphone use and sex significant?\n\n\nQUESTION 7d: Which variable indicates the interaction between smartphone use and sex?\n\n\nQUESTION 7e: And is the interaction significant?\n\n\nQUESTION 7f: What is the most reasonable interpretation of these results?\n\nThe above model uses treatment coding (sometimes called dummy coding), for the sex variable. In a categorical variable with only two levels this means that one level is coded as 0 and the other level is coded as 1. In categorical variables with more than two levels, it works slightly differently.\n\nTASK: We can check that the sex variable is treatment with the following code:\n\n\ncontrasts(smart_wb$sex)\n\nBecause we have not explicitly told R about the labels for the sex variable, it has used level 0 as the reference level, hidden within the intercept term and level sex1 describes the difference (or slope) between level 0 and 1 or in this dataset from female to male.\n\nQUESTION 7g: Is being Male better for a person’s well-being in the context of smartphone use than being Female?\n\nNow let’s look at deviation coding. There are other ways to code your categorical variables. One of them is deviation coding (also sometimes called sum coding). This effectively divides the difference of the values between your categorical levels by the number of levels so that each level can be compared to one intercept that is central to them all rather than comparing levels to one reference level. It is like centering for a categorical level.\n\nTASK Use the code chunk below to: 1) Add a variable to the smart_wb data that is a deviation coding of sex; 2) Set the deviation coding (we’ll label it ‘Sum’ here for easy variable naming); and 3) Look at the output for the sum-coded sex variable.\n\n\nsmart_wb &lt;- mutate(smart_wb, sexSum = sex) # add a variable to the smart_wb data that is a deviation coding of sex\ncontrasts(smart_wb$sexSum) &lt;- contr.sum(2) # wet the deviation coding\ncontrasts(smart_wb$sexSum) # look at the output for the sum coded sex variable\n\nNext, we’ll run the regression again, using the sum-coded sex variable and we’ll compare the outputs.\n\n# Run the regression model again, using the sumcoded sex model and compare outputs\nmod_S &lt;- lm(tot_wellbeing ~ hours_per_day + sexSum + hours_per_day:sexSum, smart_wb)\nmod_S_summary &lt;- summary(mod_S)\n\n# Compare the two model summary outputs\nmod_summary\nmod_S_summary\n\n‘sexSum1’ is now the coefficient for sex and represents the change from the intercept value which now lies between the values for being Female and Male. Note how this coefficient is negative.\nThe earlier model had a positive coefficient because the intercept described the reference group of the Girls, who on average begin at a lower well-being level than Boys (refer back to the scatterplot to verify this). Because the sum-coding has moved the intercept to a point that is the center of the difference between Boys and Girls, sexSum1 now describes the distance between the centre and a level of Sex.\nValues for well-being in Girls are thus: \\[ Intercept + sexSum*+1 = 49.74 + (-1.61)*(+1) \\]\nValues for well-being in Boys are thus: \\[Intercept + sexSum*-1 = 49.74 + (-1.61)*(-1)\\]\nwith the Boys being higher in well-being…(remember a negative number multiplied by a negative number produces a positive number and a negative number multiplied by a positive number produces a negative number).\nThe interpretation of both model effects is the same, and if you look at the summary statistics, they are identical. Deviation coding effectively centers your categorical variables and helps with interpretation of interaction terms.\n\n\nStep 8: Checking assumptions\nNow that we’ve fit a model, let’s check whether it meets the assumptions of linearity, normality and homoscedasticity. With regression models, you do this after you’ve actually fit the model.\nLinearity Unlike when we did simple regression we can’t use crPlots() to test for linearity when there is an interaction, but we know from looking at the grouped scatterplot that this assumption has been met.\nNormality Normally we would test for normality with a QQ-plot and a Shapiro-Wilk test. However, because this dataset is so large, the Shapiro-Wilk is not appropriate (if you try to run the test it will produce a warning telling you that the sample size must be between 3 and 5000). This is because with extremely large sample sizes the Shapiro-Wilk test will find that any deviation from normality is significant. Therefore we should judge normality based upon the QQ-plot.\n\nTASK: Create a QQ-plot to check the residuals are normally distributed.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou can use the qqPlot() function. The residuals are stored in the ‘mod’ object you created earlier.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nqqPlot(mod$residuals)\n\n\n\n\nQUESTION 8a: What do you conclude from the QQ-plot?\n\nHomoscedasticity Here we have the same problem as with testing for normality: with such a large sample the ncvTest() will produce a significant result for any deviation from homoscedasticity. So we need to rely on plots again. To check for homoscedasticity we can use plot() from Base R that will produce a bunch of helpful plots (more information here:.\n\nTASK: Copy the code chunk below to your script and run it.\n\n\npar(mfrow=c(2,2))             # 4 charts in 1 panel\nplot(mod)                     # this may take a few seconds to run\n\nThe residuals vs leverage plot shows a flat red line so, whilst it isn’t perfect, we can assume that with such a large sample size regression is still an appropriate analysis.\nMulti-collinearity Finally, lets check for multicollinearity using the vif() function. Essentially, this function estimates how much the variance of a coefficient is “inflated” because of linear dependence with other predictors, i.e., that a predictor isn’t actually adding any unique variance to the model, it’s just really strongly related to other predictors. Thankfully, vif is not affected by large samples like the other tests. There are various rules of thumb, but most converge on a VIF of above 2 to 2.5 for any one predictor being problematic.\n\nTASK: Copy the code chunk below to your script and run it.\n\n\nvif(mod)                      # Check for multi-collinearity\n\n\nQUESTION 8b: Do any of the predictors show evidence of multicollinearity?\n\n\n\nStep 9: Write up\n\nQUESTION 9a: How would you write up the results following APA guidance? You can choose whether you do so for the model using treatment coding or for the model using deviation coding."
  },
  {
    "objectID": "Week12.html#sec-wk12-answers",
    "href": "Week12.html#sec-wk12-answers",
    "title": "2. Categorical predictors",
    "section": "Answers",
    "text": "Answers\nWhen you have completed all of the lab content, you may want to check your answers with our completed version of the script for this week. Remember, looking at this script (studying/revising it) does not replace the process of working through the lab activities, trying them out for yourself, getting stuck, asking questions, finding solutions, adding your own comments, etc. Actively engaging with the material is the way to learn these analysis skills, not by looking at someone else’s completed code…\n\nYou can download the R-script that includes the relevant code here: 402_wk12_labAct1_withAnswers.R.\n\nLab activity 1: Combining a continuous and a categorical predictor in a regression model\n2a. In which table is the variable corresponding to sex located and what is this variable called? In pinfo; the variable is called sex.\n2b. In what format is the well-being data (long or wide)? On how many participants does it include observations? And on how many items for each participant? The well-being data are in ‘wide’ format. It contains observations on 102580 participants, on 14 items.\n2c. What is the name of the variable that identifies individual participants in this dataset? It is important to work this out as this variable will allow us to link information across the three data files. Serial\n3a. Is the distribution of well-being scores symmetrical, negatively skewed or positively skewed? Negatively skewed\n4a. What are the variables and the levels or conditions within each variable of screen2?\nParticipants plus: Levels: variables = 4: watching tv, playing video games, using computers, using smartphone day = 2 = weekdays, weekends hours = 9 = 0, 0.5, 1 - 7\n4b. What research question does this plot describe? Is it appropriate for the levels within the data? The plot describes how hours of use impact upon well-being? No, it is too broad a research question.\n4c. What research question would fit this visualisation?Is it appropriate for the levels in the data? The hours are now displayed by weekdays and weekends. How do hours of screen time impact on well-being on weekdays and at the weekend? No, it is still too broad.\n4d. What does the facet_wrap() function do? Is this plot appropriate for the levels in the data? The facet_wrap() function has split the types of screen time and shown how hours of use across weekdays and weekends impact upon well-being. This captures the levels of information within the dataset.\n5a. See the script\n6a. Write an interpretation of the above plot in plain English. Something along the lines of: Adolescent girls show lower overall well-being compared to adolescent boys. In addition, the slope for girls appears more negative than that for boys; the one for boys appears relatively flat. This suggests that the negative association between well-being and smartphone use is stronger for girls.\n7a. What is the p-value for the overall model? Is it significant? What does this mean? The p-value for the overall model fit is &lt; 2.2e-16. This significant. It means that together the predictors describe the variance in well-being better than a model without the predictors (the null model). So knowing something about smartphone use and sex of participants will allow us to predict their well-being to a degree.\n7b. To two decimal places, what percentage of the variance in well-being scores does the overall model explain? 9.38%\n7c. Are the main effects of smartphone use and sex significant? Yes.\n7d. Which variable indicates the interaction between smartphone use and sex? The interaction is indicated by the variable hours_per_day:sex.\n7e. And is the interaction significant? Yes.\n7f. What is the most reasonable interpretation of these results? Smartphone use was more negatively associated with well-being for girls than for boys.\n7g. Is being Male better for a person’s well-being in the context of smartphone use than being Female? Yes.\n8a. What do you conclude from the QQ-plot? The residuals are normally distributed.\n8b. Do any of the predictors show evidence of multicollinearity? Yes, Boys and the interaction do. We’ll talk about that more, later in the module.\n\nWrite up\n\nTreatment / dummy coded model Treatment coding was used for categorical predictors with the Girls level acting as the reference group. The results of the regression indicated that the model significantly predicted well-being (F(3, 71029) = 2450.89, p &lt; .001, Adjusted R2 = 0.09), accounting for 9% of the variance.Total hours of smart phone use was a significant negative predictor of well-being scores (β = -0.77, p &lt; .001, as was sex (β = 3.22, p &lt; .001), with girls having lower well-being scores than boys. Importantly, there was a significant interaction between screen time and sex (β = 0.45, p &lt; .001): smartphone use was more negatively associated with well-being for girls than for boys.\nDeviation / sum coded model Deviation coding was used for categorical predictors. The results of the regression indicated that the model significantly predicted well-being (F(3, 71029) = 2450.89, p &lt; .001, Adjusted R2 = 0.09), accounting for 9% of the variance. Total hours of smart phone use was a significant negative predictor of well-being scores (β = -0.55, p &lt; .001, as was sex (β = -1.61, p &lt; .001), with girls having lower well-being scores than boys. Importantly, there was a significant interaction between screen time and sex (β = -0.22, p &lt; .001), indicating that smartphone use was more negatively associated with well-being for girls than for boys."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "References\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Week14.html",
    "href": "Week14.html",
    "title": "4. Logistic regression",
    "section": "",
    "text": "All of the models considered up to this point dealt with continuous response variables. Previously we looked at categorical predictors, but what if the response itself is categorical? For instance, whether the participant has made an accurate or inaccurate selection or whether a job candidate gets hired or not. Another common type of data is count data, where values are also discrete. Often with count data, the number of opportunities for something to occur is not well-defined. For instance, the number of speech error in a corpus, the number of turn shifts between speakers in a conversation or the number of visits to the doctor. Logistic regression allows us to model a categorical response variable."
  },
  {
    "objectID": "Week14.html#sec-wk14-lectures",
    "href": "Week14.html#sec-wk14-lectures",
    "title": "4. Logistic regression",
    "section": "Lectures",
    "text": "Lectures\nThe lecture material for this week follows the recommended chapters in Winter (2020) – see under ‘Reading’ below – and is presented below:\nLogistic regression (~38 min)\n\nSlides Transcript"
  },
  {
    "objectID": "Week14.html#sec-wk14-reading",
    "href": "Week14.html#sec-wk14-reading",
    "title": "4. Logistic regression",
    "section": "Reading",
    "text": "Reading\n\nBarr (2020)\nLink\nThis online textbook provides a useful overview of logistic regression. It does talk about modelling multi-level data and random effects. Don’t worry about that for now, those will be covered in the second half of 402. This week we’ll focus on ‘single-level’ data.\n\n\nWinter (2020)\nLink\nChapter 12 provides a comprehensive introduction to logistic regression and its implementation in R."
  },
  {
    "objectID": "Week14.html#sec-wk14-pre-lab-activities",
    "href": "Week14.html#sec-wk14-pre-lab-activities",
    "title": "4. Logistic regression",
    "section": "Pre-lab activities",
    "text": "Pre-lab activities\nAfter having watched the lectures and read the textbook chapters you’ll be in a good position to try these activities. Completing them before you attend your lab session will help you to consolidate your learning and help move through the lab activities more smoothly.\n\nPre-lab activity 1: Getting ready\n\nGet your files ready\nDownload the 402_week14_forStudents.zip file and upload it into a new folder in RStudio Server.\n\n\nRemind yourself of how to access and work with the RStudio Server.\n\nSign in to the RStudio Server. Note that when you are not on campus you need to log into the VPN first (look on the portal if you need more information about that).\nCreate a new folder for this week’s work.\nUpload the zip-file to the folder you have created on the RStudio server. Note you can either upload a single file or a zip-file.\n\n\n\n\n\n\n\nIf you have difficulty uploading files to the server\n\n\n\nIf you get error messages when attempting to upload a file or a folder with files to the server, you can try the following steps:\n\nClose the R Studio server, close your browser and start afresh.\nOpen the R Studio server in a different browser.\nFollow a work around where you use code to directly download the file to the server. The code to do that will be available at the start of the lab activity where you need that particular file. The code to download the file you need to complete the quiz is below.\n\n\n\n\n\n\nPre-lab activity 2: Rainy days\nTry running the code mentioned in the online textbook by Barr. If you find it easier, use the rainy_days.R script (in the ‘402_week14_forStudents folder you were asked to download in ’Pre-lab activity 1’). It illustrates the point that for discrete data, the variance is often not independent from the mean. In addition, it introduces some very useful R functions: What do the rep() function, the c() function and the facet_wrap() function do? Remember, you can type ?function name() (e.g., ?rep()) in the Console to get more information about a function. Finally, can you add a graph for rainy days in Lancaster?\n\n\nPre-lab activity 3:Gesture perception\nPlease go through the example described in section 12.6 of the chapter on logistic regression in Bodo Winter’s book (link under ‘Reading’). Read the section and (simultaneously) work through the script (chapter12_6.R; in the ‘402_week14_forStudents folder you were asked to download in ’Pre-lab activity 1’). We’ll be working more with this dataset during the lab, so it is helpful if you get a feel for it now."
  },
  {
    "objectID": "Week14.html#sec-wk14-lab-activities",
    "href": "Week14.html#sec-wk14-lab-activities",
    "title": "4. Logistic regression",
    "section": "Lab activities",
    "text": "Lab activities\nIn this lab, you’ll gain understanding of and practice with:\n\nwhen and why to apply logistic regression to answer questions in psychological science\nconducting logistic regression in R\ninterpreting the R output of logistic regression\nreporting results for logistic regression following APA guidelines\n\nMore info will be uploaded soon.\n\nLab activity 1: More work on gesture perception\n\nBackground\nThe dataset we’ll be working with is described in section 12.6 of the chapter on logistic regression in Bodo Winter’s book (link under ‘Reading’). In the pre-lab activity, we explored the dataset and fitted a first logistic regression model assessing whether participants’ perception of a gesture (expressed as a categorical decision between a ‘shape’ vs. a ‘height’ interpretation of the gesture) was affected by the extent of ‘pinkie curl’. In this lab activity, we’ll be building on that analysis by: 1) Repeating the analysis with a centered pinkie curl variable, and 2) by adding a second predictor: index_curve.\nOur research question: Is gesture perception associated with different aspects of hand shape?\n\n\nStep 1: Set up\n\n\n\n\n\n\nSet your working directory\n\n\n\nThe folder you were asked to download under ‘Pre-lab activity 3: Getting ready for the lab class’ contains the data files we’ll need. Make sure you have set your working directory to this folder by right-clicking on it and selecting ‘Set as working directory’.\n\n\n\n\n\n\n\n\nEmpty the R environment\n\n\n\nBefore you do anything else, when starting a new analysis, it is a good idea to empty the R environment. This prevents objects and variables from previous analyses interfering with the current one. To do this, you can click on the little broom icon in the top right of the Environment pane, or you can use rm(list=ls()).\n\n\nBefore we can get started we need to tell R which libraries to use. For this analysis we’ll need broom and tidyverse.\n\nTASK: Load the relevant libraries. If you are unsure how to do that, you can look at the ‘Hint’ below for a clue by expanding it. After that, if you are still unsure, you can view the code by expanding the ‘Code’ section below.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the library() function.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below.\nlibrary(broom)\nlibrary(tidyverse)\n\n\n\n\n\n\n\n\n\nIf you couldn’t upload files to the server, do this:\n\n\n\nIf you experienced difficulties with uploading a folder or a file to the server, you can use the code below to directly download the file you need in this lab activity to the server (instead of first downloading it to you computer and then uploading it to the server). Remember that you can copy the code to your clipboard by clicking on the ‘clipboard’ in the top right corner.\n\n\n\ndownload.file(\"https://github.com/mg78/2324_PSYC402/blob/main/data/week14/hassemer_winter_2016_gesture.csv?raw=true\", destfile = \"hassemer_winter_2016_gesture.csv\")\n\n\nTASK: Finally, read in the data file (hassemer_winter_2016_gesture.csv), and familiarise yourself with its structure.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the read_csv() function and the head() function.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nThe code to do this is below.\nges &lt;- read_csv(\"hassemer_winter_2016_gesture.csv\")\nhead(ges)\n\n\n\n\n\nStep 2: Descriptive statistics and distributions\nAs part of the pre-lab activities, you’ve already familiarised yourself with the dataset by looking at:\n\nhow participants were distributed across the pinkie curl conditions;\nwhich response option was chosen more frequently in total and across pinkie curl conditions;\nproportions of response options across pinkie curl conditions\n\n\nTASK: Please remind yourself of these stages if necessary by revisiting the chaper12_6.R script.\n\n\n\nStep 3: Data wrangling\nFor logistic regression, the outcome variable needs to either be coded as 0 or 1, or it needs to be coded as a factor.\n\nTASK: Write the code to convert the outcome variable to a factor.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse mutate() and factor().\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nges &lt;- mutate(ges, choice = factor(choice))\n\n\n\nAs with linear regression, centering your predictor makes it easier to interpret the output of a logistic regression.\n\nTASK: Write the code to center the pinkie curl predictor.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nCentering involves subtracting the mean.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nges &lt;- mutate(ges,\n    pinkie_c = pinkie_curl - mean(pinkie_curl))\n\n\n\n\n\nStep 5: Fit the regression model with the centered variable\nNow let’s re-fit choice (height vs. shape) as a function of pinkie curl, but using the centered variable.\n\nTASK: Write the code to fit the model and check the coefficients.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the glm() function and remember you need to specify the ‘family’ argument. To check the coefficients, you can use the tidy() function.\n\n\n\n:::{.callout-tip collapse=“true”} ## Code\nges_mdl_c &lt;- glm(choice ~ pinkie_c,\n               data = ges, family = 'binomial')\ntidy(ges_mdl_c)\nQUESTION 1: How does the coefficient table differ from the model fitted earlier where you used the pinkie curl predictor before you centered it?\nQUESTION 2: How should you now (using the model with the centered pinkie curl predictor) interpret the intercept?\nThe average pinkie curl is step 5 on the 9 step continuum. From our previous analysis (pre-lab activity), we know that the predicted log odds of ‘shape’ at that step was 0.38 and the probability was 0.59. So if we extract the intercept from the coefficient table of the model using the centered predictor, we should get those values. Use the code below to do so and compare the values to the ones from the pre-lab activity.\n\n# Extracting the estimate for the intercept and storing it in an object called intercept:\nintercept_logOdds &lt;- tidy(ges_mdl_c)$estimate[1]\n\n# Getting the predicted probability by applying the logistic:\nintercept_prob &lt;- plogis(intercept_logOdds)\n\nintercept_logOdds\nintercept_prob\n\nThe values are roughly the same!\n\n\nStep 6: Incorporating a second predictor\nIn addition to the ‘pinkie curl’, the extent to which the index finger is curved may also affect gesture perception. This is quantified in the ‘index_curve’ variable. Before we fit the model, we need to center both predictors.\n\nTASK: Write the code to center the second predictor.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nCentering involves subtracting the mean.\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\nges &lt;- mutate(ges,\n              index_c = index_curve - mean(index_curve))\n\n\n\n\nTASK: Write the code to fit model with both pinkie curl and index curve and check the coefficients.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the glm() function and remember you need to specify the ‘family’ argument. To check the coefficients, you can use the tidy() function.\n\n\n\n:::{.callout-tip collapse=“true”} ## Code\nboth_mdl &lt;- glm(choice ~ pinkie_c + index_c,\n    data = ges, family = 'binomial')\ntidy(both_mdl)\nQUESTION 3: How does the index_curve predictor affect the proportion of shape responses?\nWe can see this more easily if we compare the descriptive proportions:\n\nindex_tab &lt;- with(ges, table(index_curve, choice))\nindex_tab\n\nprop.table(index_tab, 1)\n\nThe “1” in here stands for row-wise proportions.”2” would compute column-wise proportions."
  },
  {
    "objectID": "Week14.html#sec-wk14-answers",
    "href": "Week14.html#sec-wk14-answers",
    "title": "4. Logistic regression",
    "section": "Answers",
    "text": "Answers\nWhen you have completed all of the lab content, you may want to check your answers with our completed version of the script for this week. Remember, looking at this script (studying/revising it) does not replace the process of working through the lab activities, trying them out for yourself, getting stuck, asking questions, finding solutions, adding your own comments, etc. Actively engaging with the material is the way to learn these analysis skills, not by looking at someone else’s completed code…\n\nYou can download the R-script that includes the relevant code here: 402_wk14_labAct1_withAnswers.R.\nQUESTION 1: How does the coefficient table differ from the model fitted earlier where you used the pinkie curl predictor before you centered it? # ANSWER: The intercept has changed from 1.065 to 0.397.\nQUESTION 2: How should you now (using the model with the centered pinkie curl predictor) interpret the intercept? # ANSWER: The intercept is now the predicted log odds of ‘shape’ for a gesture with # average pinkie curl.\nQUESTION 3: How does the index_curve predictor affect the proportion of shape responses? # ANSWER: The slope is positive, so more index-curved fingers results in more # shape responses."
  }
]